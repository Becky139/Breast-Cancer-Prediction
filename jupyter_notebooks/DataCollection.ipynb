{
	"cells": [
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "0aStgWSO0E0E"
			},
			"source": [
				"# **(Data Collection Notebook)**"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "9uWZXH9LwoQg"
			},
			"source": [
				"## Objectives\n",
				"\n",
				"- Download data from Kaggle and save it as raw data.\n",
				"- Evaluate missing data\n",
				"- Inspect the data and save it under outputs/datasets/collection\n",
				"\n",
				"## Inputs\n",
				"\n",
				"Dat set from Kaggle data.csv\n",
				"\n",
				"## Outputs\n",
				"\n",
				"Generate Dataset: outputs/datasets/collection/---\n",
				"\n",
				"## Additional Comments\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "cqP-UeN-z3i2"
			},
			"source": [
				"# Change working directory"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "aOGIGS-uz3i2"
			},
			"source": [
				"We need to change the working directory from its current folder to its parent folder\n",
				"* We access the current directory with os.getcwd()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "wZfF_j-Bz3i4",
				"outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
			},
			"outputs": [],
			"source": [
				"import os\n",
				"current_dir = os.getcwd()\n",
				"current_dir"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "9MWW8E7lz3i7"
			},
			"source": [
				"We want to make the parent of the current directory the new current directory\n",
				"* os.path.dirname() gets the parent directory\n",
				"* os.chir() defines the new current directory"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "TwHsQRWjz3i9",
				"outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c",
				"tags": []
			},
			"outputs": [],
			"source": [
				"os.chdir(os.path.dirname(current_dir))\n",
				"print(\"You set a new current directory\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "M_xPk_Ijz3i-"
			},
			"source": [
				"Confirm the new current directory"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "vz3S-_kjz3jA",
				"outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
			},
			"outputs": [],
			"source": [
				"current_dir = os.getcwd()\n",
				"current_dir"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "-mavJ8DibrcQ"
			},
			"source": [
				"# Download data from Kaggle and upload"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": []
			},
			"outputs": [],
			"source": [
				"!  pip install -r requirements.txt"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": []
			},
			"outputs": [],
			"source": [
				"# importing libraries\n",
				"import numpy\n",
				"import matplotlib.pyplot as plt\n",
				"import pandas as pd\n",
				"import seaborn as sns"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "wNYS7ArHuGfT"
			},
			"source": [
				"We are using the following data from Kaggle [Kaggle URL](https://www.kaggle.com/datasets/vijayaadithyanvg/breast-cancer-prediction)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# reading data from the file\n",
				"df=pd.read_csv(\"inputs/datasets/raw/data.csv\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df.head()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "ZY3l0-AxO93d"
			},
			"source": [
				"---"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "uFQo3ycuO-v6"
			},
			"source": [
				"# Load and Inspect Kaggle data"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import pandas as pd\n",
				"df = pd.read_csv(f\"inputs/datasets/raw/data.csv\")\n",
				"df.head()"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# DataFrame Summary"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": []
			},
			"outputs": [],
			"source": [
				"df.info()"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Data Cleaning\n",
				"\n",
				"Missing or Null Data points\n",
				"\n",
				"We will find any missing or null data points of the data set (if there is any) using the following pandas function."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import pandas as pd\n",
				"df_raw_path = \"inputs/datasets/raw/data.csv\"\n",
				"df = pd.read_csv(df_raw_path)\n",
				"df.head(5)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Drop all missing or null data"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
				"vars_with_missing_data"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from ydata_profiling import ProfileReport\n",
				"if vars_with_missing_data:\n",
				"    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
				"    profile.to_notebook_iframe()\n",
				"else:\n",
				"    print(\"There are no variables with missing data\")"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Drop Duplicates"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"nr_rows = df.shape[0]\n",
				"print('Number of rows: %d' % nr_rows)\n",
				"df = df.drop_duplicates().reset_index(drop=True)\n",
				"print('Number of dropped rows: %d' % (nr_rows - df.shape[0]))\n",
				"print('Number of remainin rows: %d' % df.shape[0])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# print the first 5 rows of the dataframe\n",
				"df.head(5)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# number of rows and columns in the dataset\n",
				"df.shape"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# getting some information about the data\n",
				"df.info()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df.describe(include='all').transpose()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"---"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Split Data into Train Test and Validation Sets"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from sklearn.model_selection import train_test_split\n",
				"TrainSet, TestSet, _, __ = train_test_split(\n",
				"                                        df,\n",
				"                                        df['id'],\n",
				"                                        test_size=0.2,\n",
				"                                        random_state=0)\n",
				"\n",
				"print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"variables_method = ['id', 'diagnosis' ]\n",
				"\n",
				"print(f\"* {len(variables_method)} variables to drop \\n\\n\"\n",
				"    f\"{variables_method}\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"NOTE"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from feature_engine.selection import DropFeatures\n",
				"imputer = DropFeatures(features_to_drop=variables_method)\n",
				"imputer.fit(TrainSet)\n",
				"df_method = imputer.transform(TrainSet)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from feature_engine.selection import DropFeatures\n",
				"imputer = DropFeatures(features_to_drop=variables_method)\n",
				"imputer.fit(TrainSet)\n",
				"\n",
				"TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"* You may add as many sections as you want, as long as it supports your project workflow.\n",
				"* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"---"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"id": "ltNetd085qHf"
			},
			"source": [
				"# Push files to Repo"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"id": "aKlnIozA4eQO",
				"outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0",
				"tags": []
			},
			"outputs": [],
			"source": [
				"import os\n",
				"try:\n",
				"  os.makedirs(name='outputs/datasets/collection/cancer.csv') # create outputs/datasets/collection folder\n",
				"except Exception as e:\n",
				"  print(e)\n",
				"\n",
				"  df.to_csv(f\"outputs/datasets/collection/cancer.csv\",index=False)\n"
			]
		}
	],
	"metadata": {
		"accelerator": "GPU",
		"colab": {
			"name": "Data Practitioner Jupyter Notebook.ipynb",
			"provenance": [],
			"toc_visible": true
		},
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.8.12"
		},
		"orig_nbformat": 2
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
