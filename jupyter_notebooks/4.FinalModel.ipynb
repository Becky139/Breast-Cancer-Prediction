{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(Part 4 Feature Selection And Final Model)**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write here your notebook objective, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write here which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Breast-Cancer-Prediction/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Breast-Cancer-Prediction'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started: Load libraries and set options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# For Train , Test Spliting \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For Building Classifier Models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# For Evaluating the Accuray of the Classifiers \n",
        "from sklearn.metrics import classification_report , mean_squared_error , confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "# For  Hyper parameter Tuning \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# For Cross Validation\n",
        "from sklearn.model_selection import KFold, StratifiedKFold,cross_val_score, cross_val_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"outputs/datasets/cleaned/data.csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross-validation and Hyper-parameter Tuning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross Validation Techniques "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### K-Fold Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "logit = LogisticRegression(max_iter=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Kfold Cross Validation for our Random Forest Classifier yields 0.96 accuracy \n",
            "The Kfold Cross Validation for our Logistic Regression Classifier yields 0.94 accuracy \n",
            "The Kfold Cross Validation for our KNN Classifier yields 0.93 accuracy \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "cv1 = KFold(n_splits= 13, random_state = 12, shuffle=True)   \n",
        "\n",
        "scores_kfold_rfc = cross_val_score(RFC_model, X, Y, scoring='accuracy',cv=cv1, n_jobs=-1)\n",
        "scores_kfold_lrc = cross_val_score(LR_model, X, Y, scoring='accuracy',cv=cv1, n_jobs=-1)\n",
        "scores_kfold_knn = cross_val_score(KNNI, X, Y, scoring='accuracy',cv=cv1, n_jobs=-1)\n",
        "\n",
        "print(\"The Kfold Cross Validation for our Random Forest Classifier yields %0.2f accuracy \" % (scores_kfold_rfc.mean()))\n",
        "print(\"The Kfold Cross Validation for our Logistic Regression Classifier yields %0.2f accuracy \" % (scores_kfold_lrc.mean()))\n",
        "print(\"The Kfold Cross Validation for our KNN Classifier yields %0.2f accuracy \" % (scores_kfold_knn.mean()))\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stratified K-fold Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Kfold Cross Validation for our Random Forest Classifier yields 0.96 accuracy \n",
            "The Kfold Cross Validation for our Logistic Regression Classifier yields 0.94 accuracy \n",
            "The Kfold Cross Validation for our KNN Classifier yields 0.93 accuracy \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "skfold = StratifiedKFold(n_splits=3, random_state=100, shuffle=True)\n",
        "scores_skfold_ = cross_val_score(RFC_model, X, Y, scoring='accuracy', cv=skfold, n_jobs=-1)\n",
        "\n",
        "scores_skfold_rfc = cross_val_score(RFC_model, X, Y, scoring='accuracy',cv=skfold , n_jobs=-1)\n",
        "scores_skfold_lrc = cross_val_score(LR_model, X, Y, scoring='accuracy',cv=skfold , n_jobs=-1)\n",
        "scores_skfold_knn = cross_val_score(KNNI, X, Y, scoring='accuracy',cv=skfold , n_jobs=-1)\n",
        "\n",
        "print(\"The Kfold Cross Validation for our Random Forest Classifier yields %0.2f accuracy \" % (scores_skfold_rfc.mean()))\n",
        "print(\"The Kfold Cross Validation for our Logistic Regression Classifier yields %0.2f accuracy \" % (scores_skfold_lrc.mean()))\n",
        "print(\"The Kfold Cross Validation for our KNN Classifier yields %0.2f accuracy \" % (scores_skfold_knn.mean()))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameters Tuning With RandomizedSearch CV"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### I. RandomizedSearch CV"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the kind of search technique that moves around searching the best fit of combination in a random fashion for a fixed set of parameters over a predetermined iterations. This is the best search method incase of many numbers of hyperparameters as it reduces the computation cost. Therefore, as Random Forest Classifier depends on multiple hyperparaemters , we will be using RadomizedSearch CV for this."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The hyper parameter tuning is the process of evaluating the best fit hyperparameters set for our model. This is often refered to as search in Machine Learning models and can be categorized into two based on their best fit search patterns. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
            "[CV 1/4] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=5;, score=0.921 total time=   0.0s\n",
            "[CV 2/4] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=5;, score=0.956 total time=   0.0s\n",
            "[CV 3/4] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=5;, score=0.947 total time=   0.0s\n",
            "[CV 4/4] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=5;, score=0.929 total time=   0.0s\n",
            "[CV 2/4] END criterion=entropy, max_depth=1200, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=1200;, score=0.982 total time=   5.5s\n",
            "[CV 1/4] END criterion=entropy, max_depth=536, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=1200;, score=0.930 total time=   5.6s\n",
            "[CV 1/4] END criterion=entropy, max_depth=1200, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=1200;, score=0.939 total time=   5.8s\n",
            "[CV 3/4] END criterion=entropy, max_depth=1200, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=1200;, score=0.956 total time=   5.8s\n",
            "[CV 4/4] END criterion=entropy, max_depth=1200, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=1200;, score=0.947 total time=   5.8s\n",
            "[CV 1/4] END criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=5;, score=0.947 total time=   0.0s\n",
            "[CV 3/4] END criterion=entropy, max_depth=536, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=1200;, score=0.956 total time=   5.9s\n",
            "[CV 2/4] END criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=5;, score=0.939 total time=   0.0s\n",
            "[CV 3/4] END criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=5;, score=0.947 total time=   0.1s\n",
            "[CV 4/4] END criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=5;, score=0.947 total time=   0.1s\n",
            "[CV 4/4] END criterion=entropy, max_depth=536, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=1200;, score=0.956 total time=   6.0s\n",
            "[CV 2/4] END criterion=entropy, max_depth=536, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=1200;, score=0.982 total time=   6.2s\n",
            "[CV 1/4] END criterion=entropy, max_depth=668, max_features=None, min_samples_leaf=12, min_samples_split=14, n_estimators=1200;, score=0.904 total time=   9.0s\n",
            "[CV 3/4] END criterion=entropy, max_depth=668, max_features=None, min_samples_leaf=12, min_samples_split=14, n_estimators=1200;, score=0.939 total time=   9.0s\n",
            "[CV 4/4] END criterion=entropy, max_depth=668, max_features=None, min_samples_leaf=12, min_samples_split=14, n_estimators=1200;, score=0.947 total time=   9.6s\n",
            "[CV 2/4] END criterion=entropy, max_depth=668, max_features=None, min_samples_leaf=12, min_samples_split=14, n_estimators=1200;, score=0.974 total time=   9.8s\n",
            "[CV 3/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=1200;, score=0.956 total time=   9.8s\n",
            "[CV 1/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=1200;, score=0.930 total time=   9.8s\n",
            "[CV 1/4] END criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=5;, score=0.939 total time=   0.1s\n",
            "[CV 2/4] END criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=5;, score=0.991 total time=   0.1s\n",
            "[CV 3/4] END criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=5;, score=0.947 total time=   0.0s\n",
            "[CV 4/4] END criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=5;, score=0.956 total time=   0.0s\n",
            "[CV 2/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=1200;, score=0.974 total time=  10.6s\n",
            "[CV 4/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=1200;, score=0.947 total time=  10.6s\n",
            "[CV 1/4] END criterion=gini, max_depth=403, max_features=sqrt, min_samples_leaf=8, min_samples_split=7, n_estimators=1200;, score=0.930 total time=   5.1s\n",
            "[CV 1/4] END criterion=entropy, max_depth=801, max_features=None, min_samples_leaf=6, min_samples_split=3, n_estimators=602;, score=0.947 total time=   4.7s\n",
            "[CV 2/4] END criterion=gini, max_depth=403, max_features=sqrt, min_samples_leaf=8, min_samples_split=7, n_estimators=1200;, score=0.982 total time=   5.1s\n",
            "[CV 3/4] END criterion=entropy, max_depth=801, max_features=None, min_samples_leaf=6, min_samples_split=3, n_estimators=602;, score=0.965 total time=   4.8s\n",
            "[CV 3/4] END criterion=gini, max_depth=403, max_features=sqrt, min_samples_leaf=8, min_samples_split=7, n_estimators=1200;, score=0.947 total time=   5.1s\n",
            "[CV 4/4] END criterion=entropy, max_depth=801, max_features=None, min_samples_leaf=6, min_samples_split=3, n_estimators=602;, score=0.947 total time=   4.7s\n",
            "[CV 4/4] END criterion=gini, max_depth=403, max_features=sqrt, min_samples_leaf=8, min_samples_split=7, n_estimators=1200;, score=0.947 total time=   5.1s\n",
            "[CV 2/4] END criterion=entropy, max_depth=801, max_features=None, min_samples_leaf=6, min_samples_split=3, n_estimators=602;, score=0.974 total time=   4.9s\n",
            "[CV 1/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=12, min_samples_split=7, n_estimators=602;, score=0.912 total time=   2.7s\n",
            "[CV 2/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=12, min_samples_split=7, n_estimators=602;, score=0.974 total time=   2.7s\n",
            "[CV 3/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=12, min_samples_split=7, n_estimators=602;, score=0.939 total time=   2.3s\n",
            "[CV 4/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=12, min_samples_split=7, n_estimators=602;, score=0.947 total time=   2.3s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
              "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;],\n",
              "                                        &#x27;max_depth&#x27;: [5, 137, 270, 403, 536,\n",
              "                                                      668, 801, 934, 1067, 1200,\n",
              "                                                      None],\n",
              "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
              "                                        &#x27;min_samples_leaf&#x27;: [4, 6, 8, 12],\n",
              "                                        &#x27;min_samples_split&#x27;: [3, 7, 10, 14],\n",
              "                                        &#x27;n_estimators&#x27;: [5, 602, 1200]},\n",
              "                   random_state=101, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
              "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;],\n",
              "                                        &#x27;max_depth&#x27;: [5, 137, 270, 403, 536,\n",
              "                                                      668, 801, 934, 1067, 1200,\n",
              "                                                      None],\n",
              "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
              "                                        &#x27;min_samples_leaf&#x27;: [4, 6, 8, 12],\n",
              "                                        &#x27;min_samples_split&#x27;: [3, 7, 10, 14],\n",
              "                                        &#x27;n_estimators&#x27;: [5, 602, 1200]},\n",
              "                   random_state=101, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
              "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
              "                                        'max_depth': [5, 137, 270, 403, 536,\n",
              "                                                      668, 801, 934, 1067, 1200,\n",
              "                                                      None],\n",
              "                                        'max_features': ['sqrt', 'log2', None],\n",
              "                                        'min_samples_leaf': [4, 6, 8, 12],\n",
              "                                        'min_samples_split': [3, 7, 10, 14],\n",
              "                                        'n_estimators': [5, 602, 1200]},\n",
              "                   random_state=101, verbose=5)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "\n",
        "random_search = {'criterion': ['entropy', 'gini'],\n",
        " 'max_depth': list(np.linspace(5, 1200, 10, dtype = int)) + [None],\n",
        " 'max_features': ['sqrt','log2', None],\n",
        " 'min_samples_leaf': [4, 6, 8, 12],\n",
        " 'min_samples_split': [3, 7, 10, 14],\n",
        " 'n_estimators': list(np.linspace(5, 1200, 3, dtype = int))}\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "modelrf = RandomizedSearchCV(estimator = model ,param_distributions = random_search, cv = 4, verbose= 5, random_state= 101, n_jobs = -1)\n",
        "\n",
        "modelrf.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 1200,\n",
              " 'min_samples_split': 7,\n",
              " 'min_samples_leaf': 6,\n",
              " 'max_features': 'log2',\n",
              " 'max_depth': 1200,\n",
              " 'criterion': 'entropy'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelrf.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95        68\n",
            "           1       0.93      0.91      0.92        46\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.94      0.93      0.94       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Randomized_YPred =modelrf.predict(X_test)\n",
        "\n",
        "print(classification_report(Randomized_YPred  , Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9385964912280702"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics.accuracy_score(Y_test, Randomized_YPred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### II. GridSearch CV"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next is the GridSearch CV that is used to find the best hyperparameters for our model based on a grid based search. This is implied in the KNN model to find the best fit value for k which is the hyper parameter for that module."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After performing the search the best fit hyperparameters for our random forest model are found to be "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "params = {'n_neighbors' : list(range(1,10))}\n",
        "\n",
        "KNN_cv= GridSearchCV(KNNI,params,cv=100)\n",
        "KNN_cv.fit(X_train,Y_train)\n",
        "Y_pred  = KNN_cv.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best fit value for k is 4.\n"
          ]
        }
      ],
      "source": [
        "k = KNN_cv.best_params_.get(\"n_neighbors\")\n",
        "print(f\"The best fit value for k is {k}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9384999999999999"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "KNN_cv.best_score_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop(['diagnosis'],axis =1)\n",
        "Y = df[\"diagnosis\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the dimension of our data at the moment is 30, it is likely that the model we create is going to fall into the limitations of the curse of dimensionality. This can be solved with the use of a technique called Feature selection. This refers to the process of selecting a subset of attributes for efficient model construction."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Selecting The K Best Features for Our Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'SelectKBest' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m selected_features \u001b[39m=\u001b[39m [] \n\u001b[0;32m----> 3\u001b[0m best_features \u001b[39m=\u001b[39m SelectKBest(chi2 , k \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m)\n\u001b[1;32m      6\u001b[0m fit \u001b[39m=\u001b[39m best_features\u001b[39m.\u001b[39mfit(X , Y)\u001b[39m.\u001b[39mget_support()\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mbool\u001b[39m, feature \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(fit, df\u001b[39m.\u001b[39mcolumns):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SelectKBest' is not defined"
          ]
        }
      ],
      "source": [
        "selected_features = [] \n",
        "\n",
        "best_features = SelectKBest(chi2 , k = 5)\n",
        "\n",
        "\n",
        "fit = best_features.fit(X , Y).get_support()\n",
        "\n",
        "for bool, feature in zip(fit, df.columns):\n",
        "     if bool:\n",
        "        selected_features.append(feature)\n",
        "print(\"The best features are:{}\".format(selected_features)) # The list of your 5 best features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Viewing The Scores of the Top-k Selected Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'best_features' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m feature_scores \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(df\u001b[39m.\u001b[39mcolumns,best_features\u001b[39m.\u001b[39mfit(X , Y)\u001b[39m.\u001b[39mscores_):\n\u001b[1;32m      4\u001b[0m     feature_scores[key] \u001b[39m=\u001b[39m value\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m feature_scores\u001b[39m.\u001b[39mitems():\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_features' is not defined"
          ]
        }
      ],
      "source": [
        "feature_scores = {}\n",
        "\n",
        "for key, value in zip(df.columns,best_features.fit(X , Y).scores_):\n",
        "    feature_scores[key] = value\n",
        "\n",
        "\n",
        "for key, value in feature_scores.items():\n",
        "    if key in selected_features:\n",
        "        print(f\"{key} : {value}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Dropping Unnecessary columns/features from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = df[[\"texture_mean\" , \"perimeter_mean\" , \"perimeter_se\" , \"texture_worst\" , \"perimeter_worst\"]]\n",
        "target = df[\"diagnosis\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>8.589</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>3.398</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>4.585</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>3.445</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>5.438</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   texture_mean  perimeter_mean  perimeter_se  texture_worst  perimeter_worst\n",
              "0         10.38          122.80         8.589          17.33           184.60\n",
              "1         17.77          132.90         3.398          23.41           158.80\n",
              "2         21.25          130.00         4.585          25.53           152.50\n",
              "3         20.38           77.58         3.445          26.50            98.87\n",
              "4         14.34          135.10         5.438          16.67           152.20"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert features.shape[0] == target.shape[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Model "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Implementing KNN in our selected features using the bestfit hyper-parameters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train , X_test , Y_train , Y_test  = train_test_split(features , target , test_size = 0.33 , random_state = 42)\n",
        "\n",
        "KNN_model = KNeighborsClassifier(n_neighbors = 4).fit(X_train , Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_pred = KNN_model.predict(X_test)\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9574468085106383"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics.accuracy_score(Y_test, Y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The accuracy of KNN model after hyperparameter tuning has increased."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Implementing RandomForest Classifier in our selected features using the bestfit hyper-parameters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
            "[CV 2/4] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=5;, score=0.905 total time=   0.0s\n",
            "[CV 3/4] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=5;, score=0.947 total time=   0.0s\n",
            "[CV 4/4] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=5;, score=0.937 total time=   0.1s\n",
            "[CV 1/4] END criterion=gini, max_depth=5, max_features=sqrt, min_samples_leaf=6, min_samples_split=7, n_estimators=5;, score=0.917 total time=   0.1s\n",
            "[CV 1/4] END criterion=entropy, max_depth=1200, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=1200;, score=0.948 total time=   8.9s\n",
            "[CV 2/4] END criterion=entropy, max_depth=536, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=1200;, score=0.916 total time=   8.9s\n",
            "[CV 2/4] END criterion=entropy, max_depth=1200, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=1200;, score=0.916 total time=   9.1s\n",
            "[CV 4/4] END criterion=entropy, max_depth=536, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=1200;, score=0.926 total time=   9.1s\n",
            "[CV 4/4] END criterion=entropy, max_depth=1200, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=1200;, score=0.937 total time=   9.3s\n",
            "[CV 1/4] END criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=5;, score=0.927 total time=   0.0s\n",
            "[CV 2/4] END criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=5;, score=0.947 total time=   0.1s\n",
            "[CV 3/4] END criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=5;, score=0.937 total time=   0.0s\n",
            "[CV 1/4] END criterion=entropy, max_depth=536, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=1200;, score=0.948 total time=   9.4s\n",
            "[CV 3/4] END criterion=entropy, max_depth=1200, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=1200;, score=0.947 total time=   9.4s\n",
            "[CV 4/4] END criterion=entropy, max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=5;, score=0.905 total time=   0.0s\n",
            "[CV 2/4] END criterion=entropy, max_depth=668, max_features=None, min_samples_leaf=12, min_samples_split=14, n_estimators=1200;, score=0.947 total time=   9.5s\n",
            "[CV 3/4] END criterion=entropy, max_depth=536, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, n_estimators=1200;, score=0.947 total time=   9.4s\n",
            "[CV 1/4] END criterion=entropy, max_depth=668, max_features=None, min_samples_leaf=12, min_samples_split=14, n_estimators=1200;, score=0.948 total time=   9.5s\n",
            "[CV 4/4] END criterion=entropy, max_depth=668, max_features=None, min_samples_leaf=12, min_samples_split=14, n_estimators=1200;, score=0.937 total time=   9.5s\n",
            "[CV 3/4] END criterion=entropy, max_depth=668, max_features=None, min_samples_leaf=12, min_samples_split=14, n_estimators=1200;, score=0.905 total time=   9.5s\n",
            "[CV 2/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=1200;, score=0.937 total time=   9.6s\n",
            "[CV 1/4] END criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=5;, score=0.938 total time=   0.0s\n",
            "[CV 2/4] END criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=5;, score=0.926 total time=   0.1s\n",
            "[CV 4/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=1200;, score=0.947 total time=   9.7s\n",
            "[CV 3/4] END criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=5;, score=0.895 total time=   0.0s\n",
            "[CV 1/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=1200;, score=0.948 total time=   9.7s\n",
            "[CV 4/4] END criterion=gini, max_depth=5, max_features=log2, min_samples_leaf=12, min_samples_split=3, n_estimators=5;, score=0.895 total time=   0.0s\n",
            "[CV 3/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=14, n_estimators=1200;, score=0.937 total time=   9.8s\n",
            "[CV 2/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=12, min_samples_split=7, n_estimators=602;, score=0.947 total time=   1.6s\n",
            "[CV 4/4] END criterion=entropy, max_depth=801, max_features=None, min_samples_leaf=6, min_samples_split=3, n_estimators=602;, score=0.947 total time=   1.8s\n",
            "[CV 4/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=12, min_samples_split=7, n_estimators=602;, score=0.947 total time=   1.9s\n",
            "[CV 1/4] END criterion=entropy, max_depth=801, max_features=None, min_samples_leaf=6, min_samples_split=3, n_estimators=602;, score=0.948 total time=   2.1s\n",
            "[CV 2/4] END criterion=entropy, max_depth=801, max_features=None, min_samples_leaf=6, min_samples_split=3, n_estimators=602;, score=0.937 total time=   2.1s\n",
            "[CV 1/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=12, min_samples_split=7, n_estimators=602;, score=0.948 total time=   2.1s\n",
            "[CV 3/4] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=12, min_samples_split=7, n_estimators=602;, score=0.905 total time=   2.1s\n",
            "[CV 3/4] END criterion=entropy, max_depth=801, max_features=None, min_samples_leaf=6, min_samples_split=3, n_estimators=602;, score=0.937 total time=   2.2s\n",
            "[CV 3/4] END criterion=gini, max_depth=403, max_features=sqrt, min_samples_leaf=8, min_samples_split=7, n_estimators=1200;, score=0.926 total time=   2.7s\n",
            "[CV 1/4] END criterion=gini, max_depth=403, max_features=sqrt, min_samples_leaf=8, min_samples_split=7, n_estimators=1200;, score=0.958 total time=   3.1s\n",
            "[CV 2/4] END criterion=gini, max_depth=403, max_features=sqrt, min_samples_leaf=8, min_samples_split=7, n_estimators=1200;, score=0.926 total time=   3.1s\n",
            "[CV 4/4] END criterion=gini, max_depth=403, max_features=sqrt, min_samples_leaf=8, min_samples_split=7, n_estimators=1200;, score=0.937 total time=   3.0s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
              "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;],\n",
              "                                        &#x27;max_depth&#x27;: [5, 137, 270, 403, 536,\n",
              "                                                      668, 801, 934, 1067, 1200,\n",
              "                                                      None],\n",
              "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
              "                                        &#x27;min_samples_leaf&#x27;: [4, 6, 8, 12],\n",
              "                                        &#x27;min_samples_split&#x27;: [3, 7, 10, 14],\n",
              "                                        &#x27;n_estimators&#x27;: [5, 602, 1200]},\n",
              "                   random_state=101, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
              "                   param_distributions={&#x27;criterion&#x27;: [&#x27;entropy&#x27;, &#x27;gini&#x27;],\n",
              "                                        &#x27;max_depth&#x27;: [5, 137, 270, 403, 536,\n",
              "                                                      668, 801, 934, 1067, 1200,\n",
              "                                                      None],\n",
              "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
              "                                        &#x27;min_samples_leaf&#x27;: [4, 6, 8, 12],\n",
              "                                        &#x27;min_samples_split&#x27;: [3, 7, 10, 14],\n",
              "                                        &#x27;n_estimators&#x27;: [5, 602, 1200]},\n",
              "                   random_state=101, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
              "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
              "                                        'max_depth': [5, 137, 270, 403, 536,\n",
              "                                                      668, 801, 934, 1067, 1200,\n",
              "                                                      None],\n",
              "                                        'max_features': ['sqrt', 'log2', None],\n",
              "                                        'min_samples_leaf': [4, 6, 8, 12],\n",
              "                                        'min_samples_split': [3, 7, 10, 14],\n",
              "                                        'n_estimators': [5, 602, 1200]},\n",
              "                   random_state=101, verbose=5)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train , X_test , Y_train , Y_test  = train_test_split(features , target , test_size = 0.33 , random_state = 42)\n",
        "\n",
        "model_rf = RandomForestClassifier()\n",
        "\n",
        "RF_Model = RandomizedSearchCV(estimator = model_rf ,param_distributions = random_search, cv = 4, verbose= 5, random_state= 101, n_jobs = -1)\n",
        "\n",
        "RF_Model.fit(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9521276595744681"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_pred = RF_Model.predict(X_test)\n",
        "metrics.accuracy_score(Y_test , Y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The accuracy of Random Forest Classifier has also increased after hyperparameter tuning over the selected features."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To sum up, initially a datset that consisted of the features or details related to the infected cells present in the breast were selected and understood better with the use of available python pandas library.  After that , the matplotlib and seaborn libraries were used to visually represent or map the relationship between various features present in our dataset. \n",
        "\n",
        "Now, after that the first primary models on classification algorithms such as Logistic Regression, KNN Classifier and Random Forest Classifier were built using the sklearn library and evaluated using the available metrics. \n",
        "\n",
        "After understanding the need of the cross validation for building these models, all of these primary models were rebuilt using the K-fold and Stratified Cross Validation techniques and likewise the accuracies were checked. Both the cross validation techniques , seemed to impact the accuracy of the model in an uniform manner with **Random Forest Classifier with the highest accuracy** here.\n",
        "\n",
        "Next, was the turn to pick the best fit combination of hyperparameters for our Random Forest and KNN classifiers. Therefore, RandomizedSearch CV and GridSearch CV was used respectively to find the best combination of parameters for our models for better result. \n",
        "\n",
        "Derived Best Fit Hyper Parameters for Random Forest  : \n",
        "\n",
        "{'criterion': 'entropy', 'gini'        , <br>\n",
        " 'max_depth': 5, 137, 270, 403, 536,  668, 801, 934, 1067, 1200, None , <br>\n",
        " 'max_features': 'auto', 'sqrt', 'log2',   None, <br>\n",
        "  'min_samples_leaf': 4, 6, 8, 12,<br>\n",
        " 'min_samples_split': 3, 7, 10, 14,<br>\n",
        " 'n_estimators': 5, 602, 1200 }\n",
        "                \n",
        "Derived Best Fit Hyper Parameters for KNN Classifier  : \n",
        "\n",
        "{'n_neighbors' : 4}\n",
        "\n",
        "Finally after finding the best tuning hyper parameters for the model , the curse of dimensionality was taken into consideration and the SelectKbest feature selection technique was used to select top 5 best features from the dataset based on their scores. \n",
        "\n",
        "The best features were 'texture_mean', 'perimeter_mean', 'perimeter_se', 'texture_worst' and  'perimeter_worst'.\n",
        "\n",
        "**Finally,** after the implementation of all these refinement techniques the primarily built models were rebult by plugging in the best fit hyperparameters and selected features. **Performing this demonstrated an increase in the accuracy of the models but both our classifiers that are Random Forest And KNN appear to hold the same amount of accuracy at the end.**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
