{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(Part 5 Cross-validation and Hyper-parameter Tuning)**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "Compare with other classification methods\n",
        "   * Decision trees with **`tree.DecisionTreeClassifier()`**\n",
        "   * K-nearest neighbors with **`neighbors.KNeighborsClassifier()`**\n",
        "   * Random forests with **`ensemble.RandomForestClassifier()`**\n",
        "   * Perceptron (both gradient and stochastic gradient) with **`mlxtend.classifier.Perceptron`**\n",
        "   * Multilayer perceptron network (both gradient and stochastic gradient) with **`mlxtend.classifier.MultiLayerPerceptron`**\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write here which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Breast-Cancer-Prediction/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Breast-Cancer-Prediction'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross Validation Techniques"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### K-Fold Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv1 = KFold(n_splits= 13, random_state = 12, shuffle=True)    \n",
        "\n",
        "scores_kfold_rfc = cross_val_score(RFC_model, X, Y, scoring='accuracy',cv=cv1, n_jobs=-1)\n",
        "scores_kfold_lrc = cross_val_score(LR_model, X, Y, scoring='accuracy',cv=cv1, n_jobs=-1)\n",
        "scores_kfold_knn = cross_val_score(KNNI, X, Y, scoring='accuracy',cv=cv1, n_jobs=-1)\n",
        "\n",
        "print(\"The Kfold Cross Validation for our Random Forest Classifier yields %0.2f accuracy \" % (scores_kfold_rfc.mean()))\n",
        "print(\"The Kfold Cross Validation for our Logistic Regression Classifier yields %0.2f accuracy \" % (scores_kfold_lrc.mean()))\n",
        "print(\"The Kfold Cross Validation for our KNN Classifier yields %0.2f accuracy \" % (scores_kfold_knn.mean()))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stratified K-fold Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "skfold = StratifiedKFold(n_splits=3, random_state=100, shuffle=True)\n",
        "scores_skfold_ = cross_val_score(RFC_model, X, Y, scoring='accuracy', cv=skfold, n_jobs=-1)\n",
        "scores_skfold\n",
        "\n",
        "scores_skfold_rfc = cross_val_score(RFC_model, X, Y, scoring='accuracy',cv=skfold , n_jobs=-1)\n",
        "scores_skfold_lrc = cross_val_score(LR_model, X, Y, scoring='accuracy',cv=skfold , n_jobs=-1)\n",
        "scores_skfold_knn = cross_val_score(KNNI, X, Y, scoring='accuracy',cv=skfold , n_jobs=-1)\n",
        "\n",
        "print(\"The Kfold Cross Validation for our Random Forest Classifier yields %0.2f accuracy \" % (scores_skfold_rfc.mean()))\n",
        "print(\"The Kfold Cross Validation for our Logistic Regression Classifier yields %0.2f accuracy \" % (scores_skfold_lrc.mean()))\n",
        "print(\"The Kfold Cross Validation for our KNN Classifier yields %0.2f accuracy \" % (scores_skfold_knn.mean()))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameters Tuning With RandomizedSearch CV"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The hyper parameter tuning is the process of evaluating the best fit hyperparameters set for our model. This is often refered to as search in Machine Learning models and can be categorized into two based on their best fit search patterns. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### I. RandomizedSearch CV"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the kind of search technique that moves around searching the best fit of combination in a random fashion for a fixed set of parameters over a predetermined iterations. This is the best search method incase of many numbers of hyperparameters as it reduces the computation cost. Therefore, as Random Forest Classifier depends on multiple hyperparaemters , we will be using RadomizedSearch CV for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "\n",
        "random_search = {'criterion': ['entropy', 'gini'],\n",
        " 'max_depth': list(np.linspace(5, 1200, 10, dtype = int)) + [None],\n",
        " 'max_features': ['auto', 'sqrt','log2', None],\n",
        " 'min_samples_leaf': [4, 6, 8, 12],\n",
        " 'min_samples_split': [3, 7, 10, 14],\n",
        " 'n_estimators': list(np.linspace(5, 1200, 3, dtype = int))}\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "modelrf = RandomizedSearchCV(estimator = model ,param_distributions = random_search, cv = 4, verbose= 5, random_state= 101, n_jobs = -1)\n",
        "\n",
        "modelrf.fit(X_train, Y_train)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After performing the search the best fit hyperparameters for our random forest model are found to be "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelrf.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Randomized_YPred =modelrf.predict(X_test)\n",
        "\n",
        "print(classification_report(Randomized_YPred  , Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics.accuracy_score(Y_test, Randomized_YPred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### II. GridSearch CV"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next is the GridSearch CV that is used to find the best hyperparameters for our model based on a grid based search. This is implied in the KNN model to find the best fit value for k which is the hyper parameter for that module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "params = {'n_neighbors' : list(range(1,10))}\n",
        "\n",
        "KNN_cv= GridSearchCV(KNNI,params,cv=100)\n",
        "KNN_cv.fit(X_train,Y_train)\n",
        "Y_pred  = KNN_cv.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "k = KNN_cv.best_params_.get(\"n_neighbors\")\n",
        "print(f\"The best fit value for k is {k}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KNN_cv.best_score_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
