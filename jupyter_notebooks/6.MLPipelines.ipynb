{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(Part_6: Automate the ML process using pipelines)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write here your notebook objective, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write here which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Data Preparation and Modeling Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a pipeline that standardizes the data then creates a model\n",
        "#Load libraries for data processing\n",
        "import pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns \n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (8,4) \n",
        "#plt.rcParams['axes.titlesize'] = 'large'\n"
      ]
    },
    {
      "source": [
        "# Evaluate Some Algorithms\n",
        "\n",
        "Now it is time to create some models of the data and estimate their accuracy on unseen data. Here is what we are going to cover in this step:\n",
        "\n",
        "1.\tSeparate out a validation dataset.\n",
        "\n",
        "2.\tSetup the test harness to use 10-fold cross validation.\n",
        "\n",
        "3.\tBuild 5 different models\n",
        "\n",
        "4.\tSelect the best model\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Dataset Validation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load data\n",
        "df = pd.read_csv('data/data_clean.csv', index_col=False)\n",
        "df.drop('Unnamed: 0',axis=1, inplace=True)\n",
        "\n",
        "# Split-out validation dataset\n",
        "array = df.values\n",
        "X = array[:,1:31]\n",
        "y = array[:,0]\n",
        "\n",
        "# Divide records in training and testing sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
        "\n",
        "#transform the class labels from their original string representation (M and B) into integers\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n"
      ]
    },
    {
      "source": [
        "# Evaluate Algorithms: Baseline"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spot-Check Algorithms\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Test options and evaluation metric\n",
        "num_folds = 10\n",
        "num_instances = len(X_train)\n",
        "seed = 7 \n",
        "scoring = 'accuracy'\n",
        "\n",
        "# Test options and evaluation metric\n",
        "num_folds = 10\n",
        "num_instances = len(X_train)\n",
        "seed = 7 \n",
        "scoring = 'accuracy'\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "source": [
        "# Observation\n",
        "\n",
        "The results suggest That both Logistic Regression and LDA may be worth further study. These are just mean accuracy values. It is always wise to look at the distribution of accuracy values calculated across cross validation folds. We can do that graphically using box and whisker plots.\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare Algorithms\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()\n"
      ]
    },
    {
      "source": [
        "# Observation\n",
        "\n",
        "The results show a similar tight distribution for all classifiers except SVM which is encouraging, suggesting low variance. The good results for SVM are satisfactory.\n",
        "\n",
        "It is possible the varied distribution of the attributes may have an effect on the accuracy of algorithms such as SVM. In the next section we will repeat this spot-check with a standardized copy of the training dataset.\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Evaluate Algorithms: Standardize Data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize the dataset\n",
        "pipelines = []\n",
        "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LogisticRegression())])))\n",
        "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()),('LDA', LinearDiscriminantAnalysis())])))\n",
        "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsClassifier())])))\n",
        "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeClassifier())])))\n",
        "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB', GaussianNB())])))\n",
        "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC())])))\n",
        "\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "for name, model in pipelines:  \n",
        "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold,\n",
        "      scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "ScaledLR: 0.974936 (0.015813)\n",
        "ScaledLDA: 0.954744 (0.018784)\n",
        "ScaledKNN: 0.957372 (0.033665)\n",
        "ScaledCART: 0.927244 (0.032326)\n",
        "ScaledNB: 0.937115 (0.039261)\n",
        "ScaledSVM: 0.967436 (0.027483)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare Algorithms\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Scaled Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()\n"
      ]
    },
    {
      "source": [
        "# Observations\n",
        "\n",
        "The results show that standardization of the data has lifted the skill of SVM to be the most accurate algorithm tested so far.\n",
        "The results suggest digging deeper into the SVM and LDA and LR algorithms. It is very likely that configuration beyond the default may yield even more accurate models.\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Algorithm Tuning\n",
        "\n",
        "In this section we investigate tuning the parameters for three algorithms that show promise from the spot-checking in the previous section: LR, LDA and SVM."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "Tuning hyper-parameters - SVC estimator"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Make Support Vector Classifier Pipeline\n",
        "pipe_svc = Pipeline([('scl', StandardScaler()),\n",
        "                     ('pca', PCA(n_components=2)),\n",
        "                     ('clf', SVC(probability=True, verbose=False))])\n",
        "\n",
        "#Fit Pipeline to training Data\n",
        "pipe_svc.fit(X_train, y_train)\n",
        "\n",
        "#print('➝ Fitted Pipeline to training Data')\n",
        "\n",
        "scores = cross_val_score(estimator=pipe_svc, X=X_train, y=y_train, cv=10, n_jobs=1, verbose=0)\n",
        "print('➔ Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
        "\n",
        "#Tune Hyperparameters\n",
        "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
        "param_grid = [{'clf__C': param_range,'clf__kernel': ['linear']},\n",
        "              {'clf__C': param_range,'clf__gamma': param_range,\n",
        "               'clf__kernel': ['rbf']}]\n",
        "gs = GridSearchCV(estimator=pipe_svc,\n",
        "                  param_grid=param_grid,\n",
        "                  scoring='accuracy',\n",
        "                  cv=10,\n",
        "                  n_jobs=1)\n",
        "gs = gs.fit(X_train, y_train)\n",
        "print('➔ Tuned Parameters Best Score: ',gs.best_score_)\n",
        "print('➔ Best Parameters: \\n',gs.best_params_)\n",
        "➔ Model Training Accuracy: 0.940 +/- 0.034\n",
        "➔ Tuned Parameters Best Score:  0.9446794871794871\n",
        "➔ Best Parameters: \n",
        " {'clf__C': 1.0, 'clf__kernel': 'linear'}\n"
      ]
    },
    {
      "source": [
        "# Tuning the hyper-parameters: k-NN hyperparameters\n",
        "\n",
        "For your standard k-NN implementation, there are two primary hyperparameters that you’ll want to tune:\n",
        "\n",
        "•\tThe number of neighbors k.\n",
        "\n",
        "•\tThe distance metric/similarity function.\n",
        "\n",
        "Both of these values can dramatically affect the accuracy of your k-NN classifier. Grid object is ready to do 10-fold cross validation on a KNN model using classification accuracy as the evaluation metric In addition, there is a parameter grid to repeat the 10-fold cross validation process 30 times Each time, the n_neighbors parameter should be given a different value from the list We can't give GridSearchCV just a list We've to specify n_neighbors should take on 1 through 30 You can set n_jobs = -1 to run computations in parallel (if supported by your computer and OS)\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "\n",
        "pipe_knn = Pipeline([('scl', StandardScaler()),\n",
        "                     ('pca', PCA(n_components=2)),\n",
        "                     ('clf', KNeighborsClassifier())])\n",
        "            \n",
        "#Fit Pipeline to training Data\n",
        "pipe_knn.fit(X_train, y_train) \n",
        "\n",
        "scores = cross_val_score(estimator=pipe_knn, \n",
        "                         X=X_train, \n",
        "                         y=y_train, \n",
        "                         cv=10,\n",
        "                         n_jobs=1)\n",
        "print('➝ Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
        "\n",
        "#Tune Hyperparameters\n",
        "param_range = range(1, 31)\n",
        "param_grid = [{'clf__n_neighbors': param_range}]\n",
        "# instantiate the grid\n",
        "gs = GridSearchCV(estimator=pipe_knn, \n",
        "                    param_grid=param_grid, \n",
        "                    cv=10, \n",
        "                    scoring='accuracy')\n",
        "gs = gs.fit(X_train, y_train)\n",
        "print('➔ Tuned Parameters Best Score: ',gs.best_score_)\n",
        "print('➔ Best Parameters: \\n',gs.best_params_)\n"
      ]
    },
    {
      "source": [
        "# Finalize Model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Use best parameters\n",
        "clf_svc = gs.best_estimator_\n",
        "\n",
        "#Get Final Scores\n",
        "clf_svc.fit(X_train, y_train)\n",
        "scores = cross_val_score(estimator=clf_svc,\n",
        "                         X=X_train,\n",
        "                         y=y_train,\n",
        "                         cv=10,\n",
        "                         n_jobs=1)\n",
        "\n",
        "print('➔ Final Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
        "print('➜ Final Accuracy on Test set: %.5f' % clf_svc.score(X_test,y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_svc.fit(X_train, y_train)\n",
        "y_pred = clf_svc.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "source": [
        "# Summary\n",
        "\n",
        "Worked through a classification predictive modeling machine learning problem from end-to-end using Python. Specifically, the steps covered were:\n",
        "\n",
        "1.\tProblem Definition (Breast Cancer data).\n",
        "\n",
        "2.\tLoading the Dataset.\n",
        "\n",
        "3.\tAnalyze Data (same scale but di↵erent distributions of data).\n",
        "\n",
        "•\tEvaluate Algorithms (KNN looked good).\n",
        "\n",
        "•\tEvaluate Algorithms with Standardization (KNN and SVM looked good).\n",
        "\n",
        "4.\tAlgorithm Tuning (K=19 for KNN was good, SVM with an RBF kernel and C=100 was best)..\n",
        "\n",
        "5.\tFinalize Model (use all training data and confirm using validation dataset)\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Nov  7 2022, 16:45:55) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}