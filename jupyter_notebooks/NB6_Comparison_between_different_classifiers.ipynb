{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB6 Comparison Between Different Classifiers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "Compare with other classification methods\n",
    "   * Decision trees with **`tree.DecisionTreeClassifier()`**\n",
    "   * K-nearest neighbours with **`neighbors.KNeighborsClassifier()`**\n",
    "   * Random forests with **`ensemble.RandomForestClassifier()`**\n",
    "   * Perceptron (both gradient and stochastic gradient) with **`mlxtend.classifier.Perceptron`**\n",
    "   * Multilayer perceptron network (both gradient and stochastic gradient) with **`mlxtend.classifier.MultiLayerPerceptron`**\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* outputs/datasets/cleaned/data.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* accuracy_baseline.png, final_model_accuracy.png, final_model_classification.png, model_training_accuracy_knn.png,\n",
    "* model_training_accuracy_svc.png, scaled_algorithm.png, score_uncertainty.png, six_classifiers.png, standardize_data.png\n",
    "* compare_algorithm.jpeg, scaled_algorithm.jpeg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b1daa992-4a28-496f-b325-6e8be1a7844c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automate the ML process using pipelines \n",
    "\n",
    "There are standard workflows in a machine learning project that can be automated. In Python scikit-learn, Pipelines help to clearly define and automate these workflows.\n",
    "* Pipelines help overcome common problems like data leakage in your test harness. \n",
    "* Python scikit-learn provides a Pipeline utility to help automate machine learning workflows.\n",
    "* Pipelines work by allowing for a linear sequence of data transforms to be chained together culminating in a modelling process that can be evaluated.\n",
    "\n",
    "### Data Preparation and Modelling Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a pipeline that standardizes the data then creates a model\n",
    "# Load libraries for data processing\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Some Algorithms\n",
    "Now it is time to create some models of the data and estimate their accuracy on unseen data. Here is what we are going to cover in this step:\n",
    "1. Separate out a validation dataset.\n",
    "2. Setup the test harness to use 10-fold cross validation.\n",
    "3. Build 5 different models  \n",
    "4. Select the best model\n",
    "\n",
    "## 1.0 Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"outputs/datasets/cleaned/data.csv\", index_col=False)\n",
    "data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "# Split-out validation dataset\n",
    "array = data.values\n",
    "X = array[:, 1:31]\n",
    "y = array[:, 0]\n",
    "\n",
    "# Divide records in training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "\n",
    "# Transform the class labels from their original string representation\n",
    "# (M and B) into integers\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Evaluate Algorithms: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "models.append((\"LR\", LogisticRegression(solver=\"lbfgs\", max_iter=1000)))\n",
    "models.append((\"LDA\", LinearDiscriminantAnalysis()))\n",
    "models.append((\"KNN\", KNeighborsClassifier()))\n",
    "models.append((\"CART\", DecisionTreeClassifier()))\n",
    "models.append((\"NB\", GaussianNB()))\n",
    "models.append((\"SVM\", SVC()))\n",
    "\n",
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 7\n",
    "scoring = \"accuracy\"\n",
    "\n",
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 7\n",
    "scoring = \"accuracy\"\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    print(\n",
    "        \"\\n➔ 10-Fold cross-validation accurcay score for the training data for six classifiers\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Observation\n",
    "> The results suggest That both Logistic Regression and LDA may be worth further study. These are just mean accuracy values. It is always wise to look at the distribution of accuracy values calculated across cross validation folds. We can do that graphically using box and whisker plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.savefig(\"outputs/nb6/compare_algorithm.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "> The results show a similar tight distribution for all classifiers except SVM which is encouraging, suggesting low variance. The poor results for SVM are surprising.\n",
    "\n",
    "> It is possible the varied distribution of the attributes may have an effect on the accuracy of algorithms such as SVM. In the next section we will repeat this spot-check with a standardized copy of the training dataset.\n",
    "\n",
    "\n",
    "### 2.1 Evaluate Algorithms: Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "pipelines.append(\n",
    "    (\"ScaledLR\", Pipeline([(\"Scaler\", StandardScaler()), (\"LR\", LogisticRegression())]))\n",
    ")\n",
    "pipelines.append(\n",
    "    (\n",
    "        \"ScaledLDA\",\n",
    "        Pipeline([(\"Scaler\", StandardScaler()), (\"LDA\", LinearDiscriminantAnalysis())]),\n",
    "    )\n",
    ")\n",
    "pipelines.append(\n",
    "    (\n",
    "        \"ScaledKNN\",\n",
    "        Pipeline([(\"Scaler\", StandardScaler()), (\"KNN\", KNeighborsClassifier())]),\n",
    "    )\n",
    ")\n",
    "pipelines.append(\n",
    "    (\n",
    "        \"ScaledCART\",\n",
    "        Pipeline([(\"Scaler\", StandardScaler()), (\"CART\", DecisionTreeClassifier())]),\n",
    "    )\n",
    ")\n",
    "pipelines.append(\n",
    "    (\"ScaledNB\", Pipeline([(\"Scaler\", StandardScaler()), (\"NB\", GaussianNB())]))\n",
    ")\n",
    "pipelines.append(\n",
    "    (\"ScaledSVM\", Pipeline([(\"Scaler\", StandardScaler()), (\"SVM\", SVC())]))\n",
    ")\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Scaled Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.savefig(\"outputs/nb6/scaled_algorithm.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "> The results show that standardization of the data has lifted the skill of SVM to be the most accurate algorithm tested so far.\n",
    "\n",
    "The results suggest digging deeper into the SVM and LDA and LR algorithms. It is very likely that configuration beyond the default may yield even more accurate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Algorithm Tuning\n",
    "In this section we investigate tuning the parameters for three algorithms that show promise from the spot-checking in the previous section: LR, LDA and SVM.\n",
    "\n",
    "### Tuning hyper-parameters - SVC estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make Support Vector Classifier Pipeline\n",
    "pipe_svc = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"clf\", SVC(probability=True, verbose=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit Pipeline to training Data\n",
    "pipe_svc.fit(X_train, y_train)\n",
    "\n",
    "# print('--> Fitted Pipeline to training Data')\n",
    "\n",
    "scores = cross_val_score(\n",
    "    estimator=pipe_svc, X=X_train, y=y_train, cv=10, n_jobs=1, verbose=0\n",
    ")\n",
    "print(\"--> Model Training Accuracy: %.3f +/- %.3f\" % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "# Tune Hyperparameters\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [\n",
    "    {\"clf__C\": param_range, \"clf__kernel\": [\"linear\"]},\n",
    "    {\"clf__C\": param_range, \"clf__gamma\": param_range, \"clf__kernel\": [\"rbf\"]},\n",
    "]\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe_svc, param_grid=param_grid, scoring=\"accuracy\", cv=10, n_jobs=1\n",
    ")\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(\"➔ Tuned Parameters Best Score: \", gs.best_score_)\n",
    "print(\"➔ Best Parameters: \\n\", gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the hyper-parameters - k-NN hyperparameters\n",
    " For your standard k-NN implementation, there are two primary hyperparameters that you’ll want to tune:\n",
    "\n",
    "* The number of neighbors k.\n",
    "* The distance metric/similarity function.\n",
    "\n",
    "Both of these values can dramatically affect the accuracy of your k-NN classifier. Grid object is ready to do 10-fold cross validation on a KNN model using classification accuracy as the evaluation metric\n",
    "In addition, there is a parameter grid to repeat the 10-fold cross validation process 30 times\n",
    "Each time, the n_neighbors parameter should be given a different value from the list\n",
    "We can't give GridSearchCV just a list\n",
    "We've to specify n_neighbors should take on 1 through 30\n",
    "You can set n_jobs = -1 to run computations in parallel (if supported by your computer and OS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "pipe_knn = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"clf\", KNeighborsClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit Pipeline to training Data\n",
    "pipe_knn.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_knn, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "print(\"--> Model Training Accuracy: %.3f +/- %.3f\" % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "# Tune Hyperparameters\n",
    "param_range = range(1, 31)\n",
    "param_grid = [{\"clf__n_neighbors\": param_range}]\n",
    "# Instantiate the grid\n",
    "gs = GridSearchCV(estimator=pipe_knn, param_grid=param_grid, cv=10, scoring=\"accuracy\")\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(\"➔ Tuned Parameters Best Score: \", gs.best_score_)\n",
    "print(\"➔ Best Parameters: \\n\", gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use best parameters\n",
    "clf_svc = gs.best_estimator_\n",
    "\n",
    "# Get Final Scores\n",
    "clf_svc.fit(X_train, y_train)\n",
    "scores = cross_val_score(estimator=clf_svc, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "print(\n",
    "    \"--> Final Model Training Accuracy: %.3f +/- %.3f\"\n",
    "    % (np.mean(scores), np.std(scores))\n",
    ")\n",
    "\n",
    "print(\"--> Final Accuracy on Test set: %.5f\" % clf_svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_svc.fit(X_train, y_train)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Worked through a classification predictive modeling machine learning problem from end-to-end using Python. Specifically, the steps covered were:\n",
    "\n",
    "1. Problem Definition (Breast Cancer data).\n",
    "\n",
    "2. Loading the Dataset.\n",
    "\n",
    "3. Analyze Data (same scale but different distributions of data).\n",
    "\n",
    "    * Evaluate Algorithms (KNN looked good).\n",
    "    * Evaluate Algorithms with Standardization (KNN and SVM looked good).\n",
    "\n",
    "4. Algorithm Tuning (K=19 for KNN was good, SVM with an RBF kernel and C=100 was best).. \n",
    "5. Finalize Model (use all training data and confirm using validation dataset)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12-final"
  },
  "nbpresent": {
   "slides": {
    "24b4c65f-bb0a-40e5-82d1-e7a32fd7cb81": {
     "id": "24b4c65f-bb0a-40e5-82d1-e7a32fd7cb81",
     "prev": "c916bff9-01b0-4f88-8dfe-48366cbcebbd",
     "regions": {
      "96cec8ec-f802-4388-92b6-3575ae6d35fc": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "57b6e52c-2e81-423d-9902-e57a54fadab3",
        "part": "whole"
       },
       "id": "96cec8ec-f802-4388-92b6-3575ae6d35fc"
      }
     }
    },
    "3fe8f6e5-8355-49bd-8b72-54cc03842fdd": {
     "id": "3fe8f6e5-8355-49bd-8b72-54cc03842fdd",
     "prev": "24b4c65f-bb0a-40e5-82d1-e7a32fd7cb81",
     "regions": {
      "15ef1e17-3829-4deb-a95f-49af770554e4": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "7c2600b8-f656-4a31-8fff-826146198290",
        "part": "whole"
       },
       "id": "15ef1e17-3829-4deb-a95f-49af770554e4"
      },
      "26043033-eeee-4f5f-9f64-94e8af33b4ad": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "7b8e7745-abd5-4313-b1d9-a571faf34d6f",
        "part": "whole"
       },
       "id": "26043033-eeee-4f5f-9f64-94e8af33b4ad"
      },
      "32421559-c70d-4046-9ffb-e3fe7750d949": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "a1cd24b6-d66a-4452-a9b6-1feecc23ef3b",
        "part": "whole"
       },
       "id": "32421559-c70d-4046-9ffb-e3fe7750d949"
      },
      "6b5e1491-f4a8-4cb5-8a9a-653689ecf24f": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "2db6cf7b-a8d0-4f65-b9ba-f833f21849fd",
        "part": "whole"
       },
       "id": "6b5e1491-f4a8-4cb5-8a9a-653689ecf24f"
      },
      "82991730-4d08-4637-8391-26e15b890186": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "226eb66f-3bbc-4911-ae3e-3a7953db372a",
        "part": "whole"
       },
       "id": "82991730-4d08-4637-8391-26e15b890186"
      },
      "9c7c33ce-2582-4e10-a1b8-c334961967b6": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "aaff86c0-1ec6-4fda-bdc5-6f1fad2d1bed",
        "part": "whole"
       },
       "id": "9c7c33ce-2582-4e10-a1b8-c334961967b6"
      },
      "b852c892-5a54-4981-94b4-335b73256228": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "9e64f8b8-8d22-4b11-b893-21e18aca1896",
        "part": "whole"
       },
       "id": "b852c892-5a54-4981-94b4-335b73256228"
      },
      "bc2c634a-7f01-458a-875d-f2d9490c5d7f": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "d5d5f892-f456-4167-beca-f90a955c41b8",
        "part": "whole"
       },
       "id": "bc2c634a-7f01-458a-875d-f2d9490c5d7f"
      },
      "bee14e73-b23f-4351-949d-127e5e7725a1": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "f57a9cbe-11fb-48ec-b081-046da330c180",
        "part": "whole"
       },
       "id": "bee14e73-b23f-4351-949d-127e5e7725a1"
      },
      "c15582a0-2c07-4410-b1b3-8f6941367456": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "8b6fc11b-bdf0-4429-858b-594d9d08ffe8",
        "part": "whole"
       },
       "id": "c15582a0-2c07-4410-b1b3-8f6941367456"
      },
      "cbd8001c-ce07-4722-aed4-db80545c6aad": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "b6901fc4-1011-4b0b-a585-b408c98dccc5",
        "part": "whole"
       },
       "id": "cbd8001c-ce07-4722-aed4-db80545c6aad"
      },
      "d174d0a5-e24c-47a2-bcb3-12b795cd4d34": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "13a04041-12c5-40d9-aa3e-3c31b7c6700f",
        "part": "whole"
       },
       "id": "d174d0a5-e24c-47a2-bcb3-12b795cd4d34"
      },
      "f979a251-a052-4653-8dc4-76989d6d5564": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "4d43cfde-2f01-48e6-ae90-86aa87ed0658",
        "part": "whole"
       },
       "id": "f979a251-a052-4653-8dc4-76989d6d5564"
      },
      "fc37e2ef-dace-4e14-bd2c-d2f1720fb59b": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "f5fca3f9-acc2-4cba-9ceb-3eb63d0c6336",
        "part": "whole"
       },
       "id": "fc37e2ef-dace-4e14-bd2c-d2f1720fb59b"
      }
     }
    },
    "c916bff9-01b0-4f88-8dfe-48366cbcebbd": {
     "id": "c916bff9-01b0-4f88-8dfe-48366cbcebbd",
     "prev": null,
     "regions": {
      "b30819be-7928-4220-b15f-b3ca846f4850": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b1daa992-4a28-496f-b325-6e8be1a7844c",
        "part": "whole"
       },
       "id": "b30819be-7928-4220-b15f-b3ca846f4850"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}