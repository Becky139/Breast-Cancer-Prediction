{
	"cells": [
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "0aStgWSO0E0E"
			},
			"source": [
				"# **(Part 1 Data Collection Notebook)**"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "9uWZXH9LwoQg"
			},
			"source": [
				"## Objectives\n",
				"\n",
				"- Upload dataset to repository.\n",
				"- Load data and save it under inputs/datasets/raw/data.csv\n",
				"- Inspect the data and save it under inputs/datasets/data_clean_id/data.csv\n",
				"\n",
				"## Inputs\n",
				"\n",
				"Download  data set from Kaggle and import data.csv.\n",
				"\n",
				"## Outputs\n",
				"\n",
				"Generate Dataset:   inputs/datasets/raw/data.csv\n",
				"                    inputs/datasets/data_clean_id/data.csv\n",
				"\n",
				"## Additional Comments\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "cqP-UeN-z3i2"
			},
			"source": [
				"# Change working directory"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "aOGIGS-uz3i2"
			},
			"source": [
				"We need to change the working directory from its current folder to its parent folder\n",
				"* We access the current directory with os.getcwd()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"id": "wZfF_j-Bz3i4",
				"outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
			},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"'/workspace/Breast-Cancer-Prediction/jupyter_notebooks'"
						]
					},
					"execution_count": 1,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"import os\n",
				"current_dir = os.getcwd()\n",
				"current_dir"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "9MWW8E7lz3i7"
			},
			"source": [
				"We want to make the parent of the current directory the new current directory\n",
				"* os.path.dirname() gets the parent directory\n",
				"* os.chir() defines the new current directory"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {
				"id": "TwHsQRWjz3i9",
				"outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c",
				"tags": []
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"You set a new current directory\n"
					]
				}
			],
			"source": [
				"os.chdir(os.path.dirname(current_dir))\n",
				"print(\"You set a new current directory\")"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "M_xPk_Ijz3i-"
			},
			"source": [
				"Confirm the new current directory"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {
				"id": "vz3S-_kjz3jA",
				"outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
			},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"'/workspace/Breast-Cancer-Prediction'"
						]
					},
					"execution_count": 3,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"current_dir = os.getcwd()\n",
				"current_dir"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# 1 Problem Statement\n",
				"\n",
				"Breast cancer is the most common malignancy among women, accounting for nearly 1 in 3 cancers diagnosed among women in the United States, and it is the second leading cause of cancer death among women. Breast Cancer occurs as a result of abnormal growth of cells in the breast tissue, commonly referred to as a Tumor. A tumor does not mean cancer - tumors can be benign (not cancerous), pre-malignant (pre-cancerous), or malignant (cancerous). Tests such as MRI, mammogram, ultrasound, and biopsy are commonly used to diagnose breast cancer performed.\n",
				"\n",
				"# 1.1 Expected outcome\n",
				"\n",
				"Given breast cancer results from breast fine-needle aspiration (FNA) test (is a quick and simple procedure to perform, which removes some fluid or cells from a breast lesion or cyst (a lump, sore, or swelling) with a fine needle similar to a blood sample needle). Since this build a model that can classify a breast cancer tumor using two training classification:\n",
				"\n",
				"1 = Malignant (Cancerous) - Present\n",
				"0 = Benign (Not Cancerous) -Absent\n",
				"\n",
				"# 1.2 Objective\n",
				"\n",
				"Since the labels in the data are discrete, the predication falls into two categories, (i.e. Malignant or benign). In machine learning, this is a classification problem.\n",
				"\n",
				"Thus, the goal is to classify whether the breast cancer is benign or malignant and predict the recurrence and non-recurrence of malignant cases after a certain period. To achieve this we have used machine learning classification methods to fit a function that can predict the discrete class of new input.\n",
				"\n",
				"# 1.3 Identify data sources\n",
				"\n",
				"The Breast Cancer datasets is available as machine learning repository maintained by the University of California, Irvine. The dataset contains 569 samples of malignant and benign tumor cells.\n",
				"\n",
				"The first two columns in the dataset store the unique ID numbers of the samples and the corresponding diagnosis (M = malignant, B = benign), respectively.\n",
				"\n",
				"The columns 3-32 contain 30 real-value features that have been computed from digitized images of the cell nuclei, which can be used to build a model to predict whether a tumor is benign or malignant."
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "-mavJ8DibrcQ"
			},
			"source": [
				"# Getting Started: Load libraries and set options"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {
				"tags": []
			},
			"outputs": [],
			"source": [
				"#load libraries\n",
				"import pandas as pd\n",
				"import numpy as np \n",
				"import matplotlib.pyplot as plt\n",
				"import seaborn as sns\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"The below cell consists of all the sklearn libraries that we will be using throughout the project. It includes some modules that helps in building classifiers such as Logistic Regression, KNearest Neighbors Classifier and Random Forest Classifier. \n",
				"\n",
				"Alongside that, inorder to best fit the model the hyper parameteres of our relevant models have been tuned to find the best combination using the available search methods for which the model_selection module has been imported. \n",
				"\n",
				"Finally, given the expansive nature of the dataset, it was found better fit to incorporate dimensionality reduction techniques into our dataset. Therefore a feature selection method was used to redeem the model from the curse of dimensonality. Given this, the feature_selection module was imported.\n",
				"\n",
				"Below is the necessary list of imports that is used further.  "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [],
			"source": [
				"# For Train , Test Spliting \n",
				"from sklearn.model_selection import train_test_split\n",
				"\n",
				"# For Building Classifier Models\n",
				"from sklearn.ensemble import RandomForestClassifier\n",
				"from sklearn.linear_model import LogisticRegression\n",
				"from sklearn.neighbors import KNeighborsClassifier\n",
				"\n",
				"# For Evaluating the Accuray of the Classifiers \n",
				"from sklearn.metrics import classification_report , mean_squared_error , confusion_matrix\n",
				"from sklearn import metrics\n",
				"\n",
				"# For  Hyper parameter Tuning \n",
				"from sklearn.model_selection import RandomizedSearchCV\n",
				"from sklearn.model_selection import GridSearchCV\n",
				"\n",
				"# For Cross Validation\n",
				"from sklearn.model_selection import KFold, StratifiedKFold,cross_val_score, cross_val_predict\n",
				"\n",
				"# For Feature Selection\n",
				"from sklearn.feature_selection import SelectKBest\n",
				"from sklearn.feature_selection import chi2"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "wNYS7ArHuGfT"
			},
			"source": [
				"# Load Dataset\n",
				"\n",
				"We are using the following data from Kaggle [Kaggle URL](https://www.kaggle.com/datasets/vijayaadithyanvg/breast-cancer-prediction) I downloaded it as a csv file and imported the csv file to the repo\n",
				"\n",
				"In order to perform this task, the open source dataset platform Kaggle was used to access the dataset for a classification problem in order to build a Classifier for predicting the nature of the tumor as either maligant or benign based on certain attributes."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Read the file \"data.csv\" and print the contents.\n",
				"df = pd.read_csv(\"inputs/datasets/raw/data.csv\", index_col=False)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Inspecting the data\n",
				"\n",
				"The first step is to visually inspect the new data set. There are multiple ways to achieve this:\n",
				"\n",
				"•\tThe easiest being to request the first few records using the DataFrame data.head() method. By default,      data.head() returns the first 5 rows from the DataFrame object df (excluding the header row).\n",
				"\n",
				"•\tAlternatively, one can also use df.tail() to return the five rows of the data frame.\n",
				"\n",
				"•\tFor both head and tail methods, there is an option to specify the number of records by including the required number in between the parentheses when calling either method.Inspecting the data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>id</th>\n",
							"      <th>diagnosis</th>\n",
							"      <th>radius_mean</th>\n",
							"      <th>texture_mean</th>\n",
							"      <th>perimeter_mean</th>\n",
							"      <th>area_mean</th>\n",
							"      <th>smoothness_mean</th>\n",
							"      <th>compactness_mean</th>\n",
							"      <th>concavity_mean</th>\n",
							"      <th>concave points_mean</th>\n",
							"      <th>...</th>\n",
							"      <th>radius_worst</th>\n",
							"      <th>texture_worst</th>\n",
							"      <th>perimeter_worst</th>\n",
							"      <th>area_worst</th>\n",
							"      <th>smoothness_worst</th>\n",
							"      <th>compactness_worst</th>\n",
							"      <th>concavity_worst</th>\n",
							"      <th>concave points_worst</th>\n",
							"      <th>symmetry_worst</th>\n",
							"      <th>fractal_dimension_worst</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>0</th>\n",
							"      <td>842302</td>\n",
							"      <td>M</td>\n",
							"      <td>17.99</td>\n",
							"      <td>10.38</td>\n",
							"      <td>122.80</td>\n",
							"      <td>1001.0</td>\n",
							"      <td>0.11840</td>\n",
							"      <td>0.27760</td>\n",
							"      <td>0.3001</td>\n",
							"      <td>0.14710</td>\n",
							"      <td>...</td>\n",
							"      <td>25.38</td>\n",
							"      <td>17.33</td>\n",
							"      <td>184.60</td>\n",
							"      <td>2019.0</td>\n",
							"      <td>0.1622</td>\n",
							"      <td>0.6656</td>\n",
							"      <td>0.7119</td>\n",
							"      <td>0.2654</td>\n",
							"      <td>0.4601</td>\n",
							"      <td>0.11890</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>1</th>\n",
							"      <td>842517</td>\n",
							"      <td>M</td>\n",
							"      <td>20.57</td>\n",
							"      <td>17.77</td>\n",
							"      <td>132.90</td>\n",
							"      <td>1326.0</td>\n",
							"      <td>0.08474</td>\n",
							"      <td>0.07864</td>\n",
							"      <td>0.0869</td>\n",
							"      <td>0.07017</td>\n",
							"      <td>...</td>\n",
							"      <td>24.99</td>\n",
							"      <td>23.41</td>\n",
							"      <td>158.80</td>\n",
							"      <td>1956.0</td>\n",
							"      <td>0.1238</td>\n",
							"      <td>0.1866</td>\n",
							"      <td>0.2416</td>\n",
							"      <td>0.1860</td>\n",
							"      <td>0.2750</td>\n",
							"      <td>0.08902</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>2</th>\n",
							"      <td>84300903</td>\n",
							"      <td>M</td>\n",
							"      <td>19.69</td>\n",
							"      <td>21.25</td>\n",
							"      <td>130.00</td>\n",
							"      <td>1203.0</td>\n",
							"      <td>0.10960</td>\n",
							"      <td>0.15990</td>\n",
							"      <td>0.1974</td>\n",
							"      <td>0.12790</td>\n",
							"      <td>...</td>\n",
							"      <td>23.57</td>\n",
							"      <td>25.53</td>\n",
							"      <td>152.50</td>\n",
							"      <td>1709.0</td>\n",
							"      <td>0.1444</td>\n",
							"      <td>0.4245</td>\n",
							"      <td>0.4504</td>\n",
							"      <td>0.2430</td>\n",
							"      <td>0.3613</td>\n",
							"      <td>0.08758</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>3</th>\n",
							"      <td>84348301</td>\n",
							"      <td>M</td>\n",
							"      <td>11.42</td>\n",
							"      <td>20.38</td>\n",
							"      <td>77.58</td>\n",
							"      <td>386.1</td>\n",
							"      <td>0.14250</td>\n",
							"      <td>0.28390</td>\n",
							"      <td>0.2414</td>\n",
							"      <td>0.10520</td>\n",
							"      <td>...</td>\n",
							"      <td>14.91</td>\n",
							"      <td>26.50</td>\n",
							"      <td>98.87</td>\n",
							"      <td>567.7</td>\n",
							"      <td>0.2098</td>\n",
							"      <td>0.8663</td>\n",
							"      <td>0.6869</td>\n",
							"      <td>0.2575</td>\n",
							"      <td>0.6638</td>\n",
							"      <td>0.17300</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>4</th>\n",
							"      <td>84358402</td>\n",
							"      <td>M</td>\n",
							"      <td>20.29</td>\n",
							"      <td>14.34</td>\n",
							"      <td>135.10</td>\n",
							"      <td>1297.0</td>\n",
							"      <td>0.10030</td>\n",
							"      <td>0.13280</td>\n",
							"      <td>0.1980</td>\n",
							"      <td>0.10430</td>\n",
							"      <td>...</td>\n",
							"      <td>22.54</td>\n",
							"      <td>16.67</td>\n",
							"      <td>152.20</td>\n",
							"      <td>1575.0</td>\n",
							"      <td>0.1374</td>\n",
							"      <td>0.2050</td>\n",
							"      <td>0.4000</td>\n",
							"      <td>0.1625</td>\n",
							"      <td>0.2364</td>\n",
							"      <td>0.07678</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"<p>5 rows × 32 columns</p>\n",
							"</div>"
						],
						"text/plain": [
							"         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
							"0    842302         M        17.99         10.38          122.80     1001.0   \n",
							"1    842517         M        20.57         17.77          132.90     1326.0   \n",
							"2  84300903         M        19.69         21.25          130.00     1203.0   \n",
							"3  84348301         M        11.42         20.38           77.58      386.1   \n",
							"4  84358402         M        20.29         14.34          135.10     1297.0   \n",
							"\n",
							"   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
							"0          0.11840           0.27760          0.3001              0.14710   \n",
							"1          0.08474           0.07864          0.0869              0.07017   \n",
							"2          0.10960           0.15990          0.1974              0.12790   \n",
							"3          0.14250           0.28390          0.2414              0.10520   \n",
							"4          0.10030           0.13280          0.1980              0.10430   \n",
							"\n",
							"   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
							"0  ...         25.38          17.33           184.60      2019.0   \n",
							"1  ...         24.99          23.41           158.80      1956.0   \n",
							"2  ...         23.57          25.53           152.50      1709.0   \n",
							"3  ...         14.91          26.50            98.87       567.7   \n",
							"4  ...         22.54          16.67           152.20      1575.0   \n",
							"\n",
							"   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
							"0            0.1622             0.6656           0.7119                0.2654   \n",
							"1            0.1238             0.1866           0.2416                0.1860   \n",
							"2            0.1444             0.4245           0.4504                0.2430   \n",
							"3            0.2098             0.8663           0.6869                0.2575   \n",
							"4            0.1374             0.2050           0.4000                0.1625   \n",
							"\n",
							"   symmetry_worst  fractal_dimension_worst  \n",
							"0          0.4601                  0.11890  \n",
							"1          0.2750                  0.08902  \n",
							"2          0.3613                  0.08758  \n",
							"3          0.6638                  0.17300  \n",
							"4          0.2364                  0.07678  \n",
							"\n",
							"[5 rows x 32 columns]"
						]
					},
					"execution_count": 7,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"df.head()"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"As per the desciption provided in [Kaggle](https://www.kaggle.com/datasets/shubamsumbria/breast-cancer-prediction) , the dataset has been derived from the digital image of FNA of a breast mass.\n",
				"\n",
				"**Attribute Information:**\n",
				"\n",
				"* Diagnosis (1 = Maligant ,  0 = Benign )\n",
				"\n",
				"#### Ten real-valued features computed for each cell nucleus (3–32) referes to the followinh details:\n",
				"\n",
				"* radius : Distances from the center to points on the perimeter.\n",
				"* texture : Standard deviation of gray-scale values.\n",
				"* perimeter \n",
				"* area\n",
				"* smoothness : local variation in radius lengths.\n",
				"* compactness : perimeter² / area — 1.0.\n",
				"* concavity : severity of concave portions of the contour.\n",
				"* concave points : number of concave portions of the contour.\n",
				"* symmetry\n",
				"* fractal dimension : “coastline approximation” — 1."
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Dimension Of The Dataset"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Dimension of the dataset is 32\n"
					]
				}
			],
			"source": [
				"print(f\"Dimension of the dataset is {df.shape[1]}\")"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Checking The Features and Their Types "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"<class 'pandas.core.frame.DataFrame'>\n",
						"RangeIndex: 569 entries, 0 to 568\n",
						"Data columns (total 32 columns):\n",
						" #   Column                   Non-Null Count  Dtype  \n",
						"---  ------                   --------------  -----  \n",
						" 0   id                       569 non-null    int64  \n",
						" 1   diagnosis                569 non-null    object \n",
						" 2   radius_mean              569 non-null    float64\n",
						" 3   texture_mean             569 non-null    float64\n",
						" 4   perimeter_mean           569 non-null    float64\n",
						" 5   area_mean                569 non-null    float64\n",
						" 6   smoothness_mean          569 non-null    float64\n",
						" 7   compactness_mean         569 non-null    float64\n",
						" 8   concavity_mean           569 non-null    float64\n",
						" 9   concave points_mean      569 non-null    float64\n",
						" 10  symmetry_mean            569 non-null    float64\n",
						" 11  fractal_dimension_mean   569 non-null    float64\n",
						" 12  radius_se                569 non-null    float64\n",
						" 13  texture_se               569 non-null    float64\n",
						" 14  perimeter_se             569 non-null    float64\n",
						" 15  area_se                  569 non-null    float64\n",
						" 16  smoothness_se            569 non-null    float64\n",
						" 17  compactness_se           569 non-null    float64\n",
						" 18  concavity_se             569 non-null    float64\n",
						" 19  concave points_se        569 non-null    float64\n",
						" 20  symmetry_se              569 non-null    float64\n",
						" 21  fractal_dimension_se     569 non-null    float64\n",
						" 22  radius_worst             569 non-null    float64\n",
						" 23  texture_worst            569 non-null    float64\n",
						" 24  perimeter_worst          569 non-null    float64\n",
						" 25  area_worst               569 non-null    float64\n",
						" 26  smoothness_worst         569 non-null    float64\n",
						" 27  compactness_worst        569 non-null    float64\n",
						" 28  concavity_worst          569 non-null    float64\n",
						" 29  concave points_worst     569 non-null    float64\n",
						" 30  symmetry_worst           569 non-null    float64\n",
						" 31  fractal_dimension_worst  569 non-null    float64\n",
						"dtypes: float64(30), int64(1), object(1)\n",
						"memory usage: 142.4+ KB\n"
					]
				}
			],
			"source": [
				"df.info()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 12,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"The columns present in our dataset are as follows : \n",
						"\n",
						"id, diagnosis, radius_mean, texture_mean, perimeter_mean, area_mean, smoothness_mean, compactness_mean, concavity_mean, concave points_mean, symmetry_mean, fractal_dimension_mean, radius_se, texture_se, perimeter_se, area_se, smoothness_se, compactness_se, concavity_se, concave points_se, symmetry_se, fractal_dimension_se, radius_worst, texture_worst, perimeter_worst, area_worst, smoothness_worst, compactness_worst, concavity_worst, concave points_worst, symmetry_worst, fractal_dimension_worst, "
					]
				}
			],
			"source": [
				"print(\"The columns present in our dataset are as follows : \\n\")\n",
				"for col in df.columns:\n",
				"    print(col , end = \", \")"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Handling Missing Values \n",
				"\n",
				"#### Checking The Amount of Null Values By Columns "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"id                         0\n",
							"diagnosis                  0\n",
							"radius_mean                0\n",
							"texture_mean               0\n",
							"perimeter_mean             0\n",
							"area_mean                  0\n",
							"smoothness_mean            0\n",
							"compactness_mean           0\n",
							"concavity_mean             0\n",
							"concave points_mean        0\n",
							"symmetry_mean              0\n",
							"fractal_dimension_mean     0\n",
							"radius_se                  0\n",
							"texture_se                 0\n",
							"perimeter_se               0\n",
							"area_se                    0\n",
							"smoothness_se              0\n",
							"compactness_se             0\n",
							"concavity_se               0\n",
							"concave points_se          0\n",
							"symmetry_se                0\n",
							"fractal_dimension_se       0\n",
							"radius_worst               0\n",
							"texture_worst              0\n",
							"perimeter_worst            0\n",
							"area_worst                 0\n",
							"smoothness_worst           0\n",
							"compactness_worst          0\n",
							"concavity_worst            0\n",
							"concave points_worst       0\n",
							"symmetry_worst             0\n",
							"fractal_dimension_worst    0\n",
							"dtype: int64"
						]
					},
					"execution_count": 13,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"df.isnull().sum()"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Checking The Amount of Missing Values By Columns"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"id                         0\n",
							"diagnosis                  0\n",
							"radius_mean                0\n",
							"texture_mean               0\n",
							"perimeter_mean             0\n",
							"area_mean                  0\n",
							"smoothness_mean            0\n",
							"compactness_mean           0\n",
							"concavity_mean             0\n",
							"concave points_mean        0\n",
							"symmetry_mean              0\n",
							"fractal_dimension_mean     0\n",
							"radius_se                  0\n",
							"texture_se                 0\n",
							"perimeter_se               0\n",
							"area_se                    0\n",
							"smoothness_se              0\n",
							"compactness_se             0\n",
							"concavity_se               0\n",
							"concave points_se          0\n",
							"symmetry_se                0\n",
							"fractal_dimension_se       0\n",
							"radius_worst               0\n",
							"texture_worst              0\n",
							"perimeter_worst            0\n",
							"area_worst                 0\n",
							"smoothness_worst           0\n",
							"compactness_worst          0\n",
							"concavity_worst            0\n",
							"concave points_worst       0\n",
							"symmetry_worst             0\n",
							"fractal_dimension_worst    0\n",
							"dtype: int64"
						]
					},
					"execution_count": 14,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"df.isna().sum()"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Similarly, from the above outputs, we know that there are no missing or null values."
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"id": "ZY3l0-AxO93d"
			},
			"source": [
				"---"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Push files to Repo"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import os\n",
				"try:\n",
				"    os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/collection folder\n",
				"  # os.makedirs(name='')\n",
				"except Exception as e:\n",
				"  print(e)\n",
				"\n",
				"df.to_csv(f\"outputs/datasets/cleaned/data.csv\",index=False)"
			]
		}
	],
	"metadata": {
		"accelerator": "GPU",
		"colab": {
			"name": "Data Practitioner Jupyter Notebook.ipynb",
			"provenance": [],
			"toc_visible": true
		},
		"kernelspec": {
			"display_name": "Python 3 (ipykernel)",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.8.12"
		},
		"orig_nbformat": 2
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
