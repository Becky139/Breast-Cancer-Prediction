{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(Part 2: Exploratory Data Analysis)**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Exploratory data analysis (EDA)\n",
        "* Descriptive statistics\n",
        "* Visualization\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/datasets/data_clean_id/data.csvv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* outputs/datasets/cleaned\n",
        "\n",
        "\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Breast-Cancer-Prediction/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/Breast-Cancer-Prediction'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "source": [
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Part 2: Exploratory Data Analysis\n",
        "\n",
        "Now that we have a good intuitive sense of the data, Next step involves taking a closer look at attributes and data values. In this section, I am getting familiar with the data, which will provide useful knowledge for data pre-processing.\n",
        "\n",
        "## 2.1 Objectives of Data Exploration\n",
        "Exploratory data analysis (EDA) is a very important step which takes place after feature engineering and acquiring data and it should be done before any modeling. This is because it is very important for a data scientist to be able to understand the nature of the data without making assumptions. The results of data exploration can be extremely useful in grasping the structure of the data, the distribution of the values, and the presence of extreme values and interrelationships within the data set.\n",
        "> **The purpose of EDA is:**\n",
        "* to use summary statistics and visualizations to better understand data, \n",
        "*find clues about the tendencies of the data, its quality and to formulate assumptions and the hypothesis of our analysis\n",
        "* For data preprocessing to be successful, it is essential to have an overall picture of your data\n",
        "Basic statistical descriptions can be used to identify properties of the data and highlight which data values should be treated as noise or outliers.** \n",
        "\n",
        "Next step is to explore the data. There are two approached used to examine the data using:\n",
        "\n",
        "1. ***Descriptive statistics*** is the process of condensing key characteristics of the data set into simple numeric metrics. Some of the common metrics used are mean, standard deviation, and correlation. \n",
        "\t\n",
        "2. ***Visualization*** is the process of projecting the data, or parts of it, into Cartesian space or into abstract images. In the data mining process, data exploration is leveraged in many different steps including preprocessing, modeling, and interpretation of results. "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# 2.2 Descriptive statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Load libraries for data processing\n",
        "import pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import seaborn as sns # data visualization\n",
        "\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (15,8) \n",
        "plt.rcParams['axes.titlesize'] = 'large'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>Radius_mean</th>\n",
              "      <th>Texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.8</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.6</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>21.77</td>\n",
              "      <td>132.9</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.8</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.5</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  diagnosis  Radius_mean  Texture_mean  perimeter_mean  area_mean  \\\n",
              "0         M        17.99         10.38           122.8     1001.0   \n",
              "1         M        20.57         21.77           132.9     1326.0   \n",
              "2         M        19.69         21.25           130.0     1203.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "\n",
              "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0         0.2419  ...         25.38          17.33            184.6   \n",
              "1         0.1812  ...         24.99          23.41            158.8   \n",
              "2         0.2069  ...         23.57          25.53            152.5   \n",
              "\n",
              "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "\n",
              "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "\n",
              "[3 rows x 31 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# usind clean data with \"id\"\n",
        "df = pd.read_csv('inputs/datasets/data_clean_id/data.csv', index_col=False)\n",
        "df.drop('Unnamed: 0',axis=1, inplace=True)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Radius_mean</th>\n",
              "      <th>Texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.296678</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>...</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301816</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>...</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>...</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>...</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.870000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>...</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>...</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>...</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Radius_mean  Texture_mean  perimeter_mean    area_mean  \\\n",
              "count   569.000000    569.000000      569.000000   569.000000   \n",
              "mean     14.127292     19.296678       91.969033   654.889104   \n",
              "std       3.524049      4.301816       24.298981   351.914129   \n",
              "min       6.981000      9.710000       43.790000   143.500000   \n",
              "25%      11.700000     16.170000       75.170000   420.300000   \n",
              "50%      13.370000     18.870000       86.240000   551.100000   \n",
              "75%      15.780000     21.800000      104.100000   782.700000   \n",
              "max      28.110000     39.280000      188.500000  2501.000000   \n",
              "\n",
              "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "count       569.000000        569.000000      569.000000           569.000000   \n",
              "mean          0.096360          0.104341        0.088799             0.048919   \n",
              "std           0.014064          0.052813        0.079720             0.038803   \n",
              "min           0.052630          0.019380        0.000000             0.000000   \n",
              "25%           0.086370          0.064920        0.029560             0.020310   \n",
              "50%           0.095870          0.092630        0.061540             0.033500   \n",
              "75%           0.105300          0.130400        0.130700             0.074000   \n",
              "max           0.163400          0.345400        0.426800             0.201200   \n",
              "\n",
              "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
              "count     569.000000              569.000000  ...    569.000000   \n",
              "mean        0.181162                0.062798  ...     16.269190   \n",
              "std         0.027414                0.007060  ...      4.833242   \n",
              "min         0.106000                0.049960  ...      7.930000   \n",
              "25%         0.161900                0.057700  ...     13.010000   \n",
              "50%         0.179200                0.061540  ...     14.970000   \n",
              "75%         0.195700                0.066120  ...     18.790000   \n",
              "max         0.304000                0.097440  ...     36.040000   \n",
              "\n",
              "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
              "count     569.000000       569.000000   569.000000        569.000000   \n",
              "mean       25.677223       107.261213   880.583128          0.132369   \n",
              "std         6.146258        33.602542   569.356993          0.022832   \n",
              "min        12.020000        50.410000   185.200000          0.071170   \n",
              "25%        21.080000        84.110000   515.300000          0.116600   \n",
              "50%        25.410000        97.660000   686.500000          0.131300   \n",
              "75%        29.720000       125.400000  1084.000000          0.146000   \n",
              "max        49.540000       251.200000  4254.000000          0.222600   \n",
              "\n",
              "       compactness_worst  concavity_worst  concave points_worst  \\\n",
              "count         569.000000       569.000000            569.000000   \n",
              "mean            0.254265         0.272188              0.114606   \n",
              "std             0.157336         0.208624              0.065732   \n",
              "min             0.027290         0.000000              0.000000   \n",
              "25%             0.147200         0.114500              0.064930   \n",
              "50%             0.211900         0.226700              0.099930   \n",
              "75%             0.339100         0.382900              0.161400   \n",
              "max             1.058000         1.252000              0.291000   \n",
              "\n",
              "       symmetry_worst  fractal_dimension_worst  \n",
              "count      569.000000               569.000000  \n",
              "mean         0.290076                 0.083946  \n",
              "std          0.061867                 0.018061  \n",
              "min          0.156500                 0.055040  \n",
              "25%          0.250400                 0.071460  \n",
              "50%          0.282200                 0.080040  \n",
              "75%          0.317900                 0.092080  \n",
              "max          0.663800                 0.207500  \n",
              "\n",
              "[8 rows x 30 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#basic descriptive statistics\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1003/1665899112.py:1: FutureWarning: The default value of numeric_only in DataFrame.skew is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df.skew()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Radius_mean                0.942380\n",
              "Texture_mean               0.645592\n",
              "perimeter_mean             0.990650\n",
              "area_mean                  1.645732\n",
              "smoothness_mean            0.456324\n",
              "compactness_mean           1.190123\n",
              "concavity_mean             1.401180\n",
              "concave points_mean        1.171180\n",
              "symmetry_mean              0.725609\n",
              "fractal_dimension_mean     1.304489\n",
              "radius_se                  3.088612\n",
              "texture_se                 1.646444\n",
              "perimeter_se               3.443615\n",
              "area_se                    5.447186\n",
              "smoothness_se              2.314450\n",
              "compactness_se             1.902221\n",
              "concavity_se               5.110463\n",
              "concave points_se          1.444678\n",
              "symmetry_se                2.195133\n",
              "fractal_dimension_se       3.923969\n",
              "radius_worst               1.103115\n",
              "texture_worst              0.498321\n",
              "perimeter_worst            1.128164\n",
              "area_worst                 1.859373\n",
              "smoothness_worst           0.415426\n",
              "compactness_worst          1.473555\n",
              "concavity_worst            1.150237\n",
              "concave points_worst       0.492616\n",
              "symmetry_worst             1.433928\n",
              "fractal_dimension_worst    1.662579\n",
              "dtype: float64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.skew()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The skew result show a positive (right) or negative (left) skew. Values closer to zero show less skew.\n",
        "\n",
        "From the graphs, we can see that radius_mean, perimeter_mean, area_mean, concavity_mean and concave_points_mean are useful in predicting cancer type due to the distinct grouping between malignant and benign cancer types in these features. We can also see that area_worst and perimeter_worst are also quite useful.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['M', 'B'], dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.diagnosis.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># of observations</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diagnosis</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M</th>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           # of observations\n",
              "diagnosis                   \n",
              "B                        357\n",
              "M                        212"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Group by diagnosis and review the output.\n",
        "diag_gr = df.groupby('diagnosis', axis=0)\n",
        "pd.DataFrame(diag_gr.size(), columns=['# of observations'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check binary encoding from NB1 to confirm the coversion of the diagnosis categorical data into numeric, where\n",
        "\n",
        "•\tMalignant = 1 (indicates prescence of cancer cells)\n",
        "\n",
        "•\tBenign = 0 (indicates abscence)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Observation\n",
        "\n",
        "357 observations indicating the absence of cancer cells and 212 show absence of cancer cell\n",
        "\n",
        "Lets confirm this, by ploting the histogram\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.3 Unimodal Data Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One of the main goals of visualizing the data here is to observe which features are most helpful in predicting malignant or benign cancer. The other is to see general trends that may aid us in model selection and hyper parameter selection.\n",
        "\n",
        "We will apply 3 techniques that you can use to understand each attribute of the dataset independently.\n",
        "\n",
        "•\tHistograms.\n",
        "\n",
        "•\tDensity Plots.\n",
        "\n",
        "•\tBox and Whisker Plots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'M'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m sns\u001b[39m.\u001b[39mset_style(\u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m sns\u001b[39m.\u001b[39mset_context({\u001b[39m\"\u001b[39m\u001b[39mfigure.figsize\u001b[39m\u001b[39m\"\u001b[39m: (\u001b[39m10\u001b[39m, \u001b[39m8\u001b[39m)})\n\u001b[0;32m----> 4\u001b[0m sns\u001b[39m.\u001b[39;49mcountplot(df[\u001b[39m'\u001b[39;49m\u001b[39mdiagnosis\u001b[39;49m\u001b[39m'\u001b[39;49m],label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCount\u001b[39;49m\u001b[39m'\u001b[39;49m,palette\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSet3\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/seaborn/categorical.py:2943\u001b[0m, in \u001b[0;36mcountplot\u001b[0;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, width, dodge, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m \u001b[39melif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2941\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot pass values for both `x` and `y`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2943\u001b[0m plotter \u001b[39m=\u001b[39m _CountPlotter(\n\u001b[1;32m   2944\u001b[0m     x, y, hue, data, order, hue_order,\n\u001b[1;32m   2945\u001b[0m     estimator, errorbar, n_boot, units, seed,\n\u001b[1;32m   2946\u001b[0m     orient, color, palette, saturation,\n\u001b[1;32m   2947\u001b[0m     width, errcolor, errwidth, capsize, dodge\n\u001b[1;32m   2948\u001b[0m )\n\u001b[1;32m   2950\u001b[0m plotter\u001b[39m.\u001b[39mvalue_label \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2952\u001b[0m \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/seaborn/categorical.py:1530\u001b[0m, in \u001b[0;36m_BarPlotter.__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[1;32m   1526\u001b[0m              estimator, errorbar, n_boot, units, seed,\n\u001b[1;32m   1527\u001b[0m              orient, color, palette, saturation, width,\n\u001b[1;32m   1528\u001b[0m              errcolor, errwidth, capsize, dodge):\n\u001b[1;32m   1529\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Initialize the plotter.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1530\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestablish_variables(x, y, hue, data, orient,\n\u001b[1;32m   1531\u001b[0m                              order, hue_order, units)\n\u001b[1;32m   1532\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[1;32m   1533\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimate_statistic(estimator, errorbar, n_boot, seed)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/seaborn/categorical.py:516\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    513\u001b[0m     plot_data \u001b[39m=\u001b[39m data\n\u001b[1;32m    515\u001b[0m \u001b[39m# Convert to a list of arrays, the common representation\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m plot_data \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39masarray(d, \u001b[39mfloat\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m plot_data]\n\u001b[1;32m    518\u001b[0m \u001b[39m# The group names will just be numeric indices\u001b[39;00m\n\u001b[1;32m    519\u001b[0m group_names \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(plot_data)))\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/seaborn/categorical.py:516\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    513\u001b[0m     plot_data \u001b[39m=\u001b[39m data\n\u001b[1;32m    515\u001b[0m \u001b[39m# Convert to a list of arrays, the common representation\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m plot_data \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39;49masarray(d, \u001b[39mfloat\u001b[39;49m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m plot_data]\n\u001b[1;32m    518\u001b[0m \u001b[39m# The group names will just be numeric indices\u001b[39;00m\n\u001b[1;32m    519\u001b[0m group_names \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(plot_data)))\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/series.py:893\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    847\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[39m    Return the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39m          dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 893\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype)\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'M'"
          ]
        }
      ],
      "source": [
        "#lets get the frequency of cancer diagnosis\n",
        "sns.set_style(\"white\")\n",
        "sns.set_context({\"figure.figsize\": (10, 8)})\n",
        "sns.countplot(df['diagnosis'],label='Count',palette=\"Set3\")\n"
      ]
    },
    {
      "source": [
        "## 2.3.1 Visualise distribution of data via histograms\n",
        "Histograms are commonly used to visualize numerical variables. A histogram is similar to a bar graph after the values of the variable are grouped (binned) into a finite number of intervals (bins).\n",
        "\n",
        "Histograms group data into bins and provide you a count of the number of observations in each bin. From the shape of the bins you can quickly get a feeling for whether an attribute is Gaussian, skewed or even has an exponential distribution. It can also help you see possible outliers."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Separate columns into smaller dataframes to perform visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['id'] not in index\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Break up columns into groups, according to their suffix designation \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#(_mean, _se,and __worst) to perform visualisation plots off. \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#Join the 'ID' and 'Diagnosis' back on\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_id_diag\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39;49mloc[:,[\u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mdiagnosis\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\n\u001b[1;32m      5\u001b[0m df_diag\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mloc[:,[\u001b[39m\"\u001b[39m\u001b[39mdiagnosis\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m      7\u001b[0m \u001b[39m#For a merge + slice:\u001b[39;00m\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m   1254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[0;32m-> 1256\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    922\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    925\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1299\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1303\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1238\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m )\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1430\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1432\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1434\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['id'] not in index\""
          ]
        }
      ],
      "source": [
        "#Break up columns into groups, according to their suffix designation \n",
        "#(_mean, _se,and __worst) to perform visualisation plots off. \n",
        "#Join the 'ID' and 'Diagnosis' back on\n",
        "df_id_diag=df.loc[:,[\"id\",\"diagnosis\"]]\n",
        "df_diag=df.loc[:,[\"diagnosis\"]]\n",
        "\n",
        "#For a merge + slice:\n",
        "df_mean=df.iloc[:,1:11]\n",
        "df_se=df.iloc[:,11:22]\n",
        "df_worst=df.iloc[:,23:]\n",
        "\n",
        "print(df_id_diag.columns)\n",
        "#print(data_mean.columns)\n",
        "#print(data_se.columns)\n",
        "#print(data_worst.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Histogram the _mean suffix designition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_mean' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Plot histograms of CUT1 variables\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m hist_mean\u001b[39m=\u001b[39mdf_mean\u001b[39m.\u001b[39mhist(bins\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m, \u001b[39m10\u001b[39m),grid\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,)\n\u001b[1;32m      4\u001b[0m \u001b[39m#Any individual histograms, use this:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#df_cut['radius_worst'].hist(bins=100)\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_mean' is not defined"
          ]
        }
      ],
      "source": [
        "#Plot histograms of CUT1 variables\n",
        "hist_mean=df_mean.hist(bins=10, figsize=(15, 10),grid=False,)\n",
        "\n",
        "#Any individual histograms, use this:\n",
        "#df_cut['radius_worst'].hist(bins=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Histogram for the _se suffix designition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_se' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Plot histograms of _se variables\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m hist_se\u001b[39m=\u001b[39mdf_se\u001b[39m.\u001b[39mhist(bins\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m, \u001b[39m10\u001b[39m),grid\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_se' is not defined"
          ]
        }
      ],
      "source": [
        "#Plot histograms of _se variables\n",
        "hist_se=df_se.hist(bins=10, figsize=(15, 10),grid=False,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Histogram _worst suffix designition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Plot histograms of _worst variables\n",
        "hist_worst=df_worst.hist(bins=10, figsize=(15, 10),grid=False,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Observation\n",
        "\n",
        "We can see that perhaps the attributes concavity,and concavity_point may have an exponential distribution ( ). We can also see that perhaps the texture and smooth and symmetry attributes may have a Gaussian or nearly Gaussian distribution. This is interesting because many machine learning techniques assume a Gaussian univariate distribution on the input variables.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.3.2 Visualize distribution of data via density plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Density plots _mean suffix designition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Density Plots\n",
        "plt = df_mean.plot(kind= 'density', subplots=True, layout=(4,3), sharex=False, \n",
        "                     sharey=False, fontsize=12, figsize=(15,10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Density plots _se suffix designition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Density Plots\n",
        "plt = df_se.plot(kind= 'density', subplots=True, layout=(4,3), sharex=False, \n",
        "                    sharey=False, fontsize=12, figsize=(15,10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Density plot _worst suffix designition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Density Plots\n",
        "plt = df_worst.plot(kind= 'kde', subplots=True, layout=(4,3), sharex=False, sharey=False, \n",
        "                    fontsize=5, figsize=(15,10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Observation\n",
        "\n",
        "We can see that perhaps the attributes perimeter,radius, area, concavity, compactness may have an exponential distribution( ). We can also see that perhaps the texture and smooth and symmetry attributes may have a Gaussian or nearly Gaussian distribution. This is interesting because many machine learning techniques assume a Gaussian univariate distribution on the input variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.3.3 Visualise distribution of data via box plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Box plot _mean suffix designition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# box and whisker plots\n",
        "plt=df_mean.plot(kind= 'box' , subplots=True, layout=(4,4), sharex=False, sharey=False,\n",
        "                 fontsize=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Box plot _se suffix designition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# box and whisker plots\n",
        "plt=df_se.plot(kind= 'box' , subplots=True, layout=(4,4), sharex=False, sharey=False, \n",
        "               fontsize=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Box plot _worst suffix designition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# box and whisker plots\n",
        "plt=df_worst.plot(kind= 'box' , subplots=True, layout=(4,4), sharex=False, sharey=False, \n",
        "                  fontsize=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Observation\n",
        "\n",
        "We can see that perhaps the attributes perimeter,radius, area, concavity,ompactness may have an exponential distribution( ). We can also see that perhaps the texture and smooth and symmetry attributes may have a Gaussian or nearly Gaussian distribution. This is interesting because many machine learning techniques assume a Gaussian univariate distribution on the input variables.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.4 Multimodal Data Visualizations\n",
        "\n",
        "* Scatter plots\n",
        "* Correlation matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot correlation matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "df = pd.read_csv('data/data_clean.csv', index_col=False)\n",
        "df.drop('Unnamed: 0',axis=1, inplace=True)\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr = df_mean.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "df, ax = plt.subplots(figsize=(8, 8))\n",
        "plt.title('Breast Cancer Feature Correlation')\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(260, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, vmax=1.2, square='square', cmap=cmap, mask=mask, \n",
        "            ax=ax,annot=True, fmt='.2g',linewidths=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Observation:\n",
        "\n",
        "We can see strong positive relationship exists with mean values paramaters between 1 to 0.75.\n",
        "\n",
        "•\tThe mean area of the tissue nucleus has a strong positive correlation with mean values of radius and parameter;\n",
        "\n",
        "•\tSome paramters are moderately positive corrlated (r between 0.5-0.75)are concavity and area, concavity and perimeter etc\n",
        "\n",
        "•\tLikewise, we see some strong negative correlation between fractal_dimension with radius, texture, parameter mean values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.style.use('fivethirtyeight')\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "df = pd.read_csv('data/data_clean.csv', index_col=False)\n",
        "g = sns.PairGrid(df[[df.columns[1],df.columns[2], df.columns[3],\n",
        "                     df.columns[4], df.columns[5], df.columns[6]]], hue='diagnosis')\n",
        "g = g.map_diag(plt.hist)\n",
        "g = g.map_offdiag(plt.scatter, s = 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary:\n",
        "\n",
        "•\tMean values of cell radius, perimeter, area, compactness, concavity and concave points can be used in classification of the cancer. Larger values of these parameters tends to show a correlation with malignant tumors.\n",
        "\n",
        "•\tmean values of texture, smoothness, symmetry or fractual dimension does not show a particular preference of one diagnosis over the other.\n",
        "\n",
        "•\tIn any of the histograms there are no noticeable large outliers that warrants further cleanup.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}