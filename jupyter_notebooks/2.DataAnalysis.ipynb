{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(Part 2: Exploratory Data Analysis)**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Exploratory data analysis (EDA)\n",
        "* Descriptive statistics\n",
        "* Visualization\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/datasets/data_clean_id/data.csvv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* outputs/datasets/cleaned\n",
        "\n",
        "\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# 2.2 Descriptive statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Load libraries for data processing\n",
        "import pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import seaborn as sns # data visualization\n",
        "\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (15,8) \n",
        "plt.rcParams['axes.titlesize'] = 'large'\n",
        "In [11]:\n",
        "# usind clean data with \"id\"\n",
        "df = pd.read_csv('inputs/datasets/data_clean_id/data.csv', index_col=False)\n",
        "df.drop('Unnamed: 0',axis=1, inplace=True)\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#basic descriptive statistics\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.skew()"
      ]
    },
    {
      "source": [
        "The skew result show a positive (right) or negative (left) skew. Values closer to zero show less skew.\n",
        "\n",
        "From the graphs, we can see that radius_mean, perimeter_mean, area_mean, concavity_mean and concave_points_mean are useful in predicting cancer type due to the distinct grouping between malignant and benign cancer types in these features. We can also see that area_worst and perimeter_worst are also quite useful.\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.diagnosis.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by diagnosis and review the output.\n",
        "diag_gr = df.groupby('diagnosis', axis=0)\n",
        "pd.DataFrame(diag_gr.size(), columns=['# of observations'])\n"
      ]
    },
    {
      "source": [
        "Check binary encoding from NB1 to confirm the coversion of the diagnosis categorical data into numeric, where\n",
        "\n",
        "•\tMalignant = 1 (indicates prescence of cancer cells)\n",
        "\n",
        "•\tBenign = 0 (indicates abscence)\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Observation\n",
        "\n",
        "357 observations indicating the absence of cancer cells and 212 show absence of cancer cell\n",
        "Lets confirm this, by ploting the histogram\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "source": [
        "# 2.3 Unimodal Data Visualizations"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "One of the main goals of visualizing the data here is to observe which features are most helpful in predicting malignant or benign cancer. The other is to see general trends that may aid us in model selection and hyper parameter selection.\n",
        "\n",
        "We will apply 3 techniques that you can use to understand each attribute of the dataset independently.\n",
        "\n",
        "•\tHistograms.\n",
        "\n",
        "•\tDensity Plots.\n",
        "\n",
        "•\tBox and Whisker Plots.\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#lets get the frequency of cancer diagnosis\n",
        "sns.set_style(\"white\")\n",
        "sns.set_context({\"figure.figsize\": (10, 8)})\n",
        "sns.countplot(df['diagnosis'],label='Count',palette=\"Set3\")\n"
      ]
    },
    {
      "source": [
        "Separate columns into smaller dataframes to perform visualization"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Break up columns into groups, according to their suffix designation \n",
        "#(_mean, _se,and __worst) to perform visualisation plots off. \n",
        "#Join the 'ID' and 'Diagnosis' back on\n",
        "df_id_diag=df.loc[:,[\"id\",\"diagnosis\"]]\n",
        "df_diag=df.loc[:,[\"diagnosis\"]]\n",
        "\n",
        "#For a merge + slice:\n",
        "df_mean=df.iloc[:,1:11]\n",
        "df_se=df.iloc[:,11:22]\n",
        "df_worst=df.iloc[:,23:]\n",
        "\n",
        "print(df_id_diag.columns)\n",
        "#print(data_mean.columns)\n",
        "#print(data_se.columns)\n",
        "#print(data_worst.columns)\n",
        "Index(['id', 'diagnosis'], dtype='object')\n"
      ]
    },
    {
      "source": [
        "# Histogram the _mean suffix designition"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Plot histograms of CUT1 variables\n",
        "hist_mean=df_mean.hist(bins=10, figsize=(15, 10),grid=False,)\n",
        "\n",
        "#Any individual histograms, use this:\n",
        "#df_cut['radius_worst'].hist(bins=100)\n"
      ]
    },
    {
      "source": [
        "# Histogram for the _se suffix designition"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Plot histograms of _se variables\n",
        "hist_se=df_se.hist(bins=10, figsize=(15, 10),grid=False,)\n"
      ]
    },
    {
      "source": [
        "# Histogram _worst suffix designition"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Plot histograms of _worst variables\n",
        "hist_worst=df_worst.hist(bins=10, figsize=(15, 10),grid=False,)\n"
      ]
    },
    {
      "source": [
        "# Observation\n",
        "\n",
        "We can see that perhaps the attributes concavity,and concavity_point may have an exponential distribution ( ). We can also see that perhaps the texture and smooth and symmetry attributes may have a Gaussian or nearly Gaussian distribution. This is interesting because many machine learning techniques assume a Gaussian univariate distribution on the input variables.\n",
        "\n",
        "---\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# 2.3.2 Visualize distribution of data via density plots\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Density plots _mean suffix designition"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Density Plots\n",
        "plt = df_mean.plot(kind= 'density', subplots=True, layout=(4,3), sharex=False, \n",
        "                     sharey=False, fontsize=12, figsize=(15,10))\n"
      ]
    },
    {
      "source": [
        "# Density plots _se suffix designition"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Density Plots\n",
        "plt = df_se.plot(kind= 'density', subplots=True, layout=(4,3), sharex=False, \n",
        "                    sharey=False, fontsize=12, figsize=(15,10))\n"
      ]
    },
    {
      "source": [
        "# Density plot _worst suffix designition"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Density Plots\n",
        "plt = df_worst.plot(kind= 'kde', subplots=True, layout=(4,3), sharex=False, sharey=False, \n",
        "                    fontsize=5, figsize=(15,10))\n"
      ]
    },
    {
      "source": [
        "# Observation\n",
        "\n",
        "We can see that perhaps the attributes perimeter,radius, area, concavity, compactness may have an exponential distribution( ). We can also see that perhaps the texture and smooth and symmetry attributes may have a Gaussian or nearly Gaussian distribution. This is interesting because many machine learning techniques assume a Gaussian univariate distribution on the input variables.\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# 2.3.3 Visualise distribution of data via box plots"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Box plot _mean suffix designition"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# box and whisker plots\n",
        "plt=df_mean.plot(kind= 'box' , subplots=True, layout=(4,4), sharex=False, sharey=False,\n",
        "                 fontsize=12)\n"
      ]
    },
    {
      "source": [
        "# Box plot _se suffix designition"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# box and whisker plots\n",
        "plt=df_se.plot(kind= 'box' , subplots=True, layout=(4,4), sharex=False, sharey=False, \n",
        "               fontsize=12)\n"
      ]
    },
    {
      "source": [
        "# Box plot _worst suffix designition"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# box and whisker plots\n",
        "plt=df_worst.plot(kind= 'box' , subplots=True, layout=(4,4), sharex=False, sharey=False, \n",
        "                  fontsize=12)\n"
      ]
    },
    {
      "source": [
        "# Observation\n",
        "\n",
        "We can see that perhaps the attributes perimeter,radius, area, concavity,ompactness may have an exponential distribution( ). We can also see that perhaps the texture and smooth and symmetry attributes may have a Gaussian or nearly Gaussian distribution. This is interesting because many machine learning techniques assume a Gaussian univariate distribution on the input variables.\n",
        "\n",
        "---\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# 2.4 Multimodal Data Visualizations"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Correlation matrix"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot correlation matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "df = pd.read_csv('data/data_clean.csv', index_col=False)\n",
        "df.drop('Unnamed: 0',axis=1, inplace=True)\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr = df_mean.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "df, ax = plt.subplots(figsize=(8, 8))\n",
        "plt.title('Breast Cancer Feature Correlation')\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(260, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, vmax=1.2, square='square', cmap=cmap, mask=mask, \n",
        "            ax=ax,annot=True, fmt='.2g',linewidths=2)\n"
      ]
    },
    {
      "source": [
        "# Observation:\n",
        "\n",
        "We can see strong positive relationship exists with mean values paramaters between 1 to 0.75.\n",
        "\n",
        "•\tThe mean area of the tissue nucleus has a strong positive correlation with mean values of radius and parameter;\n",
        "\n",
        "•\tSome paramters are moderately positive corrlated (r between 0.5-0.75)are concavity and area, concavity and perimeter etc\n",
        "\n",
        "•\tLikewise, we see some strong negative correlation between fractal_dimension with radius, texture, parameter mean values.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.style.use('fivethirtyeight')\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "df = pd.read_csv('data/data_clean.csv', index_col=False)\n",
        "g = sns.PairGrid(df[[df.columns[1],df.columns[2], df.columns[3],\n",
        "                     df.columns[4], df.columns[5], df.columns[6]]], hue='diagnosis')\n",
        "g = g.map_diag(plt.hist)\n",
        "g = g.map_offdiag(plt.scatter, s = 3)\n"
      ]
    },
    {
      "source": [
        "# Summary:\n",
        "\n",
        "•\tMean values of cell radius, perimeter, area, compactness, concavity and concave points can be used in classification of the cancer. Larger values of these parameters tends to show a correlation with malignant tumors.\n",
        "\n",
        "•\tmean values of texture, smoothness, symmetry or fractual dimension does not show a particular preference of one diagnosis over the other.\n",
        "\n",
        "•\tIn any of the histograms there are no noticeable large outliers that warrants further cleanup.\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}